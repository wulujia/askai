+++
date = '2025-02-25T07:28:30+08:00'
draft = false
title = 'flomo 向量化的效果'
+++

flomo 的创始人说：flomo “相关笔记”使用了向量化，效果很不错。这里的“向量化”具体是怎么做？能在“相关笔记”功能里起到什么效果？

> 向量化在“相关笔记”功能中的具体应用可以涉及多个方面，例如自然语言处理（NLP）中的词向量、句向量、文档向量等。为了更准确回答您的问题，您是否可以提供更多信息？例如：
> 
> - 您是希望了解向量化在技术上的实现方式（如 TF-IDF、Word2Vec、BERT、Embedding 等）？
> - 还是更关注它在“相关笔记”功能中的具体作用，如如何计算笔记之间的相关性？
> - 该“相关笔记”功能是 Flomo 内部的实现，还是您在自己的产品中想要参考应用？

1. 更关注它在“相关笔记”功能中的具体作用，如如何计算笔记之间的相关性？
2. 这是 flomo 中的实现，也就是把可能有关联的笔记关联起来。
3. 我在思考，知识星球里可以有什么样的应用？

> 好的，我将研究 Flomo 在“相关笔记”功能中使用向量化技术的具体方式，以及它如何计算笔记之间的相关性。此外，我会探讨类似的方法如何应用于知识星球，以帮助实现更智能的内容关联和推荐。我会尽快给您反馈！

# Flomo「相关笔记」功能的向量化技术分析

**Flomo 利用向量化实现笔记关联**：Flomo 的“相关笔记”功能通过**向量化文本内容**来计算笔记之间的相似性。简单来说，就是把每条笔记转换成一个高维向量表示，然后比较这些向量来判断笔记内容的相近程度 ([對話flomo少楠：當然會對AI感到恐慌，但別著急 - 新浪香港](https://portal.sina.com.hk/technology/sina/2024/12/03/1064617/%E5%B0%8D%E8%A9%B1flomo%E5%B0%91%E6%A5%A0%EF%BC%9A%E7%95%B6%E7%84%B6%E6%9C%83%E5%B0%8Dai%E6%84%9F%E5%88%B0%E6%81%90%E6%85%8C%EF%BC%8C%E4%BD%86%E5%88%A5%E8%91%97%E6%80%A5/#:~:text=%E5%90%8C%E6%A8%A3%E7%9A%84%E9%81%93%E7%90%86%EF%BC%8C%E6%AF%94%E5%A6%82%E6%88%91%E5%80%91%E4%B9%8B%E5%89%8D%E6%8F%90%E5%88%B0%E7%9A%84%E5%8D%A1%E7%89%87%E7%AD%86%E8%A8%98%E6%B3%95%EF%BC%8C%E9%81%8E%E5%8E%BB%E5%83%8F%E7%9B%A7%E6%9B%BC%E9%82%A3%E6%A8%A3%EF%BC%8C%E6%AF%8F%E5%BC%B5%E5%8D%A1%E7%89%87%E9%83%BD%E8%A6%81%E6%89%8B%E5%AF%AB%E7%B7%A8%E7%A2%BC%EF%BC%8C%E7%84%B6%E5%BE%8C%E8%87%AA%E5%B7%B1%E6%95%B4%E7%90%86%EF%BC%8C%E6%89%BE%E9%97%9C%E8%81%AF%E7%9A%84%E5%8D%A1%E7%89%87%E8%A6%81%E7%BF%BB%E5%8D%8A%E5%A4%A9%EF%BC%8C%E9%80%99%E5%BE%88%E7%B4%AF%E4%BA%BA%E3%80%82%E4%BD%86%E7%8F%BE%E5%9C%A8%E6%9C%89%E4%BA%86%20AI%20%E5%92%8C%E5%90%91%E9%87%8F%E5%8C%96%E6%8A%80%E8%A1%93%EF%BC%8C%E6%88%91%E5%80%91%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%B8%80%E5%BC%B5%E5%8D%A1%E7%89%87%E4%B8%8A%E6%93%81%E6%9C%89%201000%20%E5%A4%9A%E5%80%8B%E7%B6%AD%E5%BA%A6%EF%BC%8C%E9%80%9A%E9%81%8E%E9%80%99%E4%BA%9B%E7%B6%AD%E5%BA%A6%E8%88%87%E5%8F%A6%E4%B8%80%E5%BC%B5%E5%8D%A1%E7%89%87%E9%80%B2%E8%A1%8C%E9%97%9C%E8%81%AF%EF%BC%8CAI,%E5%8F%AF%E4%BB%A5%E5%B9%AB%E5%8A%A9%E6%88%91%E5%80%91%E7%99%BC%E7%8F%BE%E5%85%A9%E5%BC%B5%E5%8D%A1%E7%89%87%E4%B9%8B%E9%96%93%E7%9A%84%E8%81%AF%E7%B9%AB%EF%BC%8C%E5%95%9F%E7%99%BC%E6%88%91%E5%80%91%E6%80%9D%E8%80%83%E3%80%82%E9%80%99%E6%A8%A3%EF%BC%8C%E6%88%91%E5%80%91%E5%B0%B1%E5%8F%AF%E4%BB%A5%E6%8A%8A%E7%BF%BB%E6%89%BE%E5%8D%A1%E7%89%87%E7%9A%84%E9%81%8E%E7%A8%8B%E7%9C%81%E7%95%A5%E6%8E%89%EF%BC%8C%E7%95%99%E5%87%BA%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%99%82%E9%96%93%E5%8E%BB%E5%81%9A%E6%9B%B4%E9%87%8D%E8%A6%81%E7%9A%84%E4%BA%8B%E6%83%85%E3%80%82))。Flomo 联合创始人少楠提到，借助 AI 的向量化技术，每张卡片笔记可被表示为包含上千维特征的向量，通过这些维度来自动关联其它相似的笔记卡片 ([對話flomo少楠：當然會對AI感到恐慌，但別著急 - 新浪香港](https://portal.sina.com.hk/technology/sina/2024/12/03/1064617/%E5%B0%8D%E8%A9%B1flomo%E5%B0%91%E6%A5%A0%EF%BC%9A%E7%95%B6%E7%84%B6%E6%9C%83%E5%B0%8Dai%E6%84%9F%E5%88%B0%E6%81%90%E6%85%8C%EF%BC%8C%E4%BD%86%E5%88%A5%E8%91%97%E6%80%A5/#:~:text=%E5%90%8C%E6%A8%A3%E7%9A%84%E9%81%93%E7%90%86%EF%BC%8C%E6%AF%94%E5%A6%82%E6%88%91%E5%80%91%E4%B9%8B%E5%89%8D%E6%8F%90%E5%88%B0%E7%9A%84%E5%8D%A1%E7%89%87%E7%AD%86%E8%A8%98%E6%B3%95%EF%BC%8C%E9%81%8E%E5%8E%BB%E5%83%8F%E7%9B%A7%E6%9B%BC%E9%82%A3%E6%A8%A3%EF%BC%8C%E6%AF%8F%E5%BC%B5%E5%8D%A1%E7%89%87%E9%83%BD%E8%A6%81%E6%89%8B%E5%AF%AB%E7%B7%A8%E7%A2%BC%EF%BC%8C%E7%84%B6%E5%BE%8C%E8%87%AA%E5%B7%B1%E6%95%B4%E7%90%86%EF%BC%8C%E6%89%BE%E9%97%9C%E8%81%AF%E7%9A%84%E5%8D%A1%E7%89%87%E8%A6%81%E7%BF%BB%E5%8D%8A%E5%A4%A9%EF%BC%8C%E9%80%99%E5%BE%88%E7%B4%AF%E4%BA%BA%E3%80%82%E4%BD%86%E7%8F%BE%E5%9C%A8%E6%9C%89%E4%BA%86%20AI%20%E5%92%8C%E5%90%91%E9%87%8F%E5%8C%96%E6%8A%80%E8%A1%93%EF%BC%8C%E6%88%91%E5%80%91%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%B8%80%E5%BC%B5%E5%8D%A1%E7%89%87%E4%B8%8A%E6%93%81%E6%9C%89%201000%20%E5%A4%9A%E5%80%8B%E7%B6%AD%E5%BA%A6%EF%BC%8C%E9%80%9A%E9%81%8E%E9%80%99%E4%BA%9B%E7%B6%AD%E5%BA%A6%E8%88%87%E5%8F%A6%E4%B8%80%E5%BC%B5%E5%8D%A1%E7%89%87%E9%80%B2%E8%A1%8C%E9%97%9C%E8%81%AF%EF%BC%8CAI,%E5%8F%AF%E4%BB%A5%E5%B9%AB%E5%8A%A9%E6%88%91%E5%80%91%E7%99%BC%E7%8F%BE%E5%85%A9%E5%BC%B5%E5%8D%A1%E7%89%87%E4%B9%8B%E9%96%93%E7%9A%84%E8%81%AF%E7%B9%AB%EF%BC%8C%E5%95%9F%E7%99%BC%E6%88%91%E5%80%91%E6%80%9D%E8%80%83%E3%80%82%E9%80%99%E6%A8%A3%EF%BC%8C%E6%88%91%E5%80%91%E5%B0%B1%E5%8F%AF%E4%BB%A5%E6%8A%8A%E7%BF%BB%E6%89%BE%E5%8D%A1%E7%89%87%E7%9A%84%E9%81%8E%E7%A8%8B%E7%9C%81%E7%95%A5%E6%8E%89%EF%BC%8C%E7%95%99%E5%87%BA%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%99%82%E9%96%93%E5%8E%BB%E5%81%9A%E6%9B%B4%E9%87%8D%E8%A6%81%E7%9A%84%E4%BA%8B%E6%83%85%E3%80%82))。这意味着每条笔记都被转换为一个**语义向量**，相当于让 AI **理解笔记的语义**，从而可以跨越表面关键词找到语义相关的内容 ([刚上手flomo的「相关笔记」功能， 连续体验了好几个，超出 - 即刻App](https://m.okjike.com/originalPosts/66445c839e2e9fda028e9aa2#:~:text=%E6%83%8A%E5%96%9C%E5%9C%A8%E4%BA%8EAI%E5%85%85%E5%88%86%E7%90%86%E8%A7%A3%E4%BA%86%E5%8D%A1%E7%89%87%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%20%E5%B9%B6%E4%BB%8E%E6%95%B4%E4%B8%AA4000%E5%A4%9A%E6%9D%A1%E7%AC%94%E8%AE%B0%E4%B8%AD%E6%89%BE%E5%88%B0%E6%AF%94%E8%BE%83%E7%9B%B8%E5%85%B3%E7%9A%84%EF%BC%8C%20%E8%80%8C%E4%B8%94%E6%98%AF%E3%80%8C%E8%AF%AD%E4%B9%89%E3%80%8D%E7%BA%A7%E5%88%AB%E7%9A%84%E7%9B%B8%E5%85%B3%EF%BC%81%20%E5%8F%A6%E5%A4%96%EF%BC%8C%E6%8E%A8%E8%8D%90%E7%9A%84%E5%8D%A1%E7%89%87%E4%B8%8D%E5%8F%AA%E6%98%AF%E3%80%8C%E7%9B%B8%E5%85%B3%E3%80%8D%EF%BC%8C%20%E8%80%8C%E6%98%AF%E8%83%BD%E3%80%8C%E6%89%93%E5%BC%80%E6%80%9D%E8%B7%AF%E3%80%8D%EF%BC%8C%E9%A1%BA%E7%9D%80%E5%B0%B1%E8%83%BD%E4%BA%A7%E7%94%9F%E6%80%9D%E8%80%83%EF%BC%8C,%E8%BF%99%E5%AF%B9%E4%BA%8E%E5%86%99%E4%BD%9C%E5%92%8C%E6%BF%80%E5%8F%91%E6%80%9D%E8%80%83%E6%9D%A5%E8%AF%B4%E9%9D%9E%E5%B8%B8%E9%87%8D%E8%A6%81%E3%80%82))。

## 向量化方法：从 TF-IDF 到 BERT

**传统方法（TF-IDF 等）**：早期的文本相似度计算通常使用 TF-IDF 向量等**稀疏向量**表示方法。TF-IDF 将文档表示为基于词频的高维稀疏向量，每个维度对应一个词汇 ([〖AI学习〗RAG与推荐系统_rag 推荐系统-CSDN博客](https://blog.csdn.net/bylander/article/details/138199906#:~:text=%E7%A8%A0%E5%AF%86%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%EF%BC%88Dense%20Retriever%EF%BC%89%E6%98%AF%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88NLP%EF%BC%89%E5%92%8C%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E9%A2%86%E5%9F%9F%E4%B8%AD%E7%9A%84%E4%B8%80%E4%B8%AA%E6%9C%AF%E8%AF%AD%EF%BC%8C%E5%AE%83%E6%8C%87%E7%9A%84%E6%98%AF%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%AF%86%E9%9B%86%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%E7%9A%84%E6%96%87%E6%A1%A3%E6%A3%80%E7%B4%A2%E6%96%B9%E6%B3%95%E3%80%82%E8%BF%99%E7%A7%8D%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%89%80%E4%BB%A5%E8%A2%AB%E7%A7%B0%20%E4%B8%BA%E2%80%9C%E7%A8%A0%E5%AF%86%E2%80%9D%EF%BC%88Dense%EF%BC%89%EF%BC%8C%E6%98%AF%E5%9B%A0%E4%B8%BA%E5%AE%83%E4%BB%AC%E4%BD%BF%E7%94%A8%E8%BF%9E%E7%BB%AD%E7%9A%84%E3%80%81%E7%A8%A0%E5%AF%86%E7%9A%84%E5%90%91%E9%87%8F%EF%BC%88%E9%80%9A%E5%B8%B8%E6%98%AF%E5%AE%9E%E6%95%B0%E5%90%91%E9%87%8F%EF%BC%89%E6%9D%A5%E8%A1%A8%E7%A4%BA%E6%9F%A5%E8%AF%A2%EF%BC%88query%EF%BC%89%E5%92%8C%E6%96%87%E6%A1%A3%EF%BC%88document%EF%BC%89%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BC%A0%E7%BB%9F%E7%9A%84%E7%A8%80%E7%96%8F%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%E3%80%82%20%E5%9C%A8%E4%BC%A0%E7%BB%9F%E7%9A%84%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%E4%B8%AD%EF%BC%8C%E6%96%87%E6%A1%A3%E5%92%8C%E6%9F%A5%E8%AF%A2%E9%80%9A%E5%B8%B8%E6%98%AF%E9%80%9A%E8%BF%87%E7%A8%80%E7%96%8F%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%E7%9A%84%EF%BC%8C%E4%BE%8B%E5%A6%82%E4%BD%BF%E7%94%A8TF,Words%EF%BC%89%EF%BC%8C%E5%85%B6%E4%B8%AD%E5%90%91%E9%87%8F%E4%B8%AD%E7%9A%84%E6%AF%8F%E4%B8%AA%E5%85%83%E7%B4%A0%E5%AF%B9%E5%BA%94%E4%BA%8E%E8%AF%8D%E6%B1%87%E8%A1%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%B8%AA%E5%8D%95%E8%AF%8D%EF%BC%8C%E5%B9%B6%E4%B8%94%E5%8F%AA%E6%9C%89%E5%8D%95%E8%AF%8D%E5%87%BA%E7%8E%B0%E6%97%B6%E5%85%83%E7%B4%A0%E6%89%8D%E9%9D%9E%E9%9B%B6%E3%80%82%20%E7%9B%B8%E6%AF%94%E4%B9%8B%E4%B8%8B%EF%BC%8C%E7%A8%A0%E5%AF%86%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%EF%BC%8C%E5%A6%82%E5%8F%98%E6%8D%A2%E5%99%A8%EF%BC%88Transformers%EF%BC%89%E6%88%96BERT%EF%BC%88Bidirectional%20Encoder))。这种方法计算简单，但只能反映关键词重合度，无法理解上下文语义。例如，两个笔记如果用不同词表达相似含义，TF-IDF 可能无法识别它们的关联。

**语义嵌入（Word2Vec/BERT 等）**：Flomo 引入的是更先进的**语义向量化技术**。这通常利用预训练的语言模型（如 **Word2Vec**、**Doc2Vec**、**Sentence-BERT** 或其他 Transformer 模型）将整条笔记映射为一个**密集向量**。相比 TF-IDF 的稀疏词袋模型，深度模型生成的向量在连续空间中捕捉了语义特征 ([〖AI学习〗RAG与推荐系统_rag 推荐系统-CSDN博客](https://blog.csdn.net/bylander/article/details/138199906#:~:text=%E7%A8%A0%E5%AF%86%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%EF%BC%88Dense%20Retriever%EF%BC%89%E6%98%AF%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88NLP%EF%BC%89%E5%92%8C%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E9%A2%86%E5%9F%9F%E4%B8%AD%E7%9A%84%E4%B8%80%E4%B8%AA%E6%9C%AF%E8%AF%AD%EF%BC%8C%E5%AE%83%E6%8C%87%E7%9A%84%E6%98%AF%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%AF%86%E9%9B%86%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%E7%9A%84%E6%96%87%E6%A1%A3%E6%A3%80%E7%B4%A2%E6%96%B9%E6%B3%95%E3%80%82%E8%BF%99%E7%A7%8D%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%89%80%E4%BB%A5%E8%A2%AB%E7%A7%B0%20%E4%B8%BA%E2%80%9C%E7%A8%A0%E5%AF%86%E2%80%9D%EF%BC%88Dense%EF%BC%89%EF%BC%8C%E6%98%AF%E5%9B%A0%E4%B8%BA%E5%AE%83%E4%BB%AC%E4%BD%BF%E7%94%A8%E8%BF%9E%E7%BB%AD%E7%9A%84%E3%80%81%E7%A8%A0%E5%AF%86%E7%9A%84%E5%90%91%E9%87%8F%EF%BC%88%E9%80%9A%E5%B8%B8%E6%98%AF%E5%AE%9E%E6%95%B0%E5%90%91%E9%87%8F%EF%BC%89%E6%9D%A5%E8%A1%A8%E7%A4%BA%E6%9F%A5%E8%AF%A2%EF%BC%88query%EF%BC%89%E5%92%8C%E6%96%87%E6%A1%A3%EF%BC%88document%EF%BC%89%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BC%A0%E7%BB%9F%E7%9A%84%E7%A8%80%E7%96%8F%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%E3%80%82%20%E5%9C%A8%E4%BC%A0%E7%BB%9F%E7%9A%84%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%E4%B8%AD%EF%BC%8C%E6%96%87%E6%A1%A3%E5%92%8C%E6%9F%A5%E8%AF%A2%E9%80%9A%E5%B8%B8%E6%98%AF%E9%80%9A%E8%BF%87%E7%A8%80%E7%96%8F%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%E7%9A%84%EF%BC%8C%E4%BE%8B%E5%A6%82%E4%BD%BF%E7%94%A8TF,Words%EF%BC%89%EF%BC%8C%E5%85%B6%E4%B8%AD%E5%90%91%E9%87%8F%E4%B8%AD%E7%9A%84%E6%AF%8F%E4%B8%AA%E5%85%83%E7%B4%A0%E5%AF%B9%E5%BA%94%E4%BA%8E%E8%AF%8D%E6%B1%87%E8%A1%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%B8%AA%E5%8D%95%E8%AF%8D%EF%BC%8C%E5%B9%B6%E4%B8%94%E5%8F%AA%E6%9C%89%E5%8D%95%E8%AF%8D%E5%87%BA%E7%8E%B0%E6%97%B6%E5%85%83%E7%B4%A0%E6%89%8D%E9%9D%9E%E9%9B%B6%E3%80%82%20%E7%9B%B8%E6%AF%94%E4%B9%8B%E4%B8%8B%EF%BC%8C%E7%A8%A0%E5%AF%86%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%EF%BC%8C%E5%A6%82%E5%8F%98%E6%8D%A2%E5%99%A8%EF%BC%88Transformers%EF%BC%89%E6%88%96BERT%EF%BC%88Bidirectional%20Encoder))。例如，BERT 等模型能根据上下文为句子生成768维或更高维度的向量表示，包含语义和语法信息。少楠提到 Flomo 每条卡片有“1000 多个维度”，暗示他们可能使用了类似 BERT 的**高维语义嵌入**来表示笔记 ([對話flomo少楠：當然會對AI感到恐慌，但別著急 - 新浪香港](https://portal.sina.com.hk/technology/sina/2024/12/03/1064617/%E5%B0%8D%E8%A9%B1flomo%E5%B0%91%E6%A5%A0%EF%BC%9A%E7%95%B6%E7%84%B6%E6%9C%83%E5%B0%8Dai%E6%84%9F%E5%88%B0%E6%81%90%E6%85%8C%EF%BC%8C%E4%BD%86%E5%88%A5%E8%91%97%E6%80%A5/#:~:text=%E5%90%8C%E6%A8%A3%E7%9A%84%E9%81%93%E7%90%86%EF%BC%8C%E6%AF%94%E5%A6%82%E6%88%91%E5%80%91%E4%B9%8B%E5%89%8D%E6%8F%90%E5%88%B0%E7%9A%84%E5%8D%A1%E7%89%87%E7%AD%86%E8%A8%98%E6%B3%95%EF%BC%8C%E9%81%8E%E5%8E%BB%E5%83%8F%E7%9B%A7%E6%9B%BC%E9%82%A3%E6%A8%A3%EF%BC%8C%E6%AF%8F%E5%BC%B5%E5%8D%A1%E7%89%87%E9%83%BD%E8%A6%81%E6%89%8B%E5%AF%AB%E7%B7%A8%E7%A2%BC%EF%BC%8C%E7%84%B6%E5%BE%8C%E8%87%AA%E5%B7%B1%E6%95%B4%E7%90%86%EF%BC%8C%E6%89%BE%E9%97%9C%E8%81%AF%E7%9A%84%E5%8D%A1%E7%89%87%E8%A6%81%E7%BF%BB%E5%8D%8A%E5%A4%A9%EF%BC%8C%E9%80%99%E5%BE%88%E7%B4%AF%E4%BA%BA%E3%80%82%E4%BD%86%E7%8F%BE%E5%9C%A8%E6%9C%89%E4%BA%86%20AI%20%E5%92%8C%E5%90%91%E9%87%8F%E5%8C%96%E6%8A%80%E8%A1%93%EF%BC%8C%E6%88%91%E5%80%91%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%B8%80%E5%BC%B5%E5%8D%A1%E7%89%87%E4%B8%8A%E6%93%81%E6%9C%89%201000%20%E5%A4%9A%E5%80%8B%E7%B6%AD%E5%BA%A6%EF%BC%8C%E9%80%9A%E9%81%8E%E9%80%99%E4%BA%9B%E7%B6%AD%E5%BA%A6%E8%88%87%E5%8F%A6%E4%B8%80%E5%BC%B5%E5%8D%A1%E7%89%87%E9%80%B2%E8%A1%8C%E9%97%9C%E8%81%AF%EF%BC%8CAI,%E5%8F%AF%E4%BB%A5%E5%B9%AB%E5%8A%A9%E6%88%91%E5%80%91%E7%99%BC%E7%8F%BE%E5%85%A9%E5%BC%B5%E5%8D%A1%E7%89%87%E4%B9%8B%E9%96%93%E7%9A%84%E8%81%AF%E7%B9%AB%EF%BC%8C%E5%95%9F%E7%99%BC%E6%88%91%E5%80%91%E6%80%9D%E8%80%83%E3%80%82%E9%80%99%E6%A8%A3%EF%BC%8C%E6%88%91%E5%80%91%E5%B0%B1%E5%8F%AF%E4%BB%A5%E6%8A%8A%E7%BF%BB%E6%89%BE%E5%8D%A1%E7%89%87%E7%9A%84%E9%81%8E%E7%A8%8B%E7%9C%81%E7%95%A5%E6%8E%89%EF%BC%8C%E7%95%99%E5%87%BA%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%99%82%E9%96%93%E5%8E%BB%E5%81%9A%E6%9B%B4%E9%87%8D%E8%A6%81%E7%9A%84%E4%BA%8B%E6%83%85%E3%80%82))。这种向量化使得即使两条笔记没有出现相同的词，只要语义相关，其向量在高维空间里也会相近，从而被识别出来 ([刚上手flomo的「相关笔记」功能， 连续体验了好几个，超出 - 即刻App](https://m.okjike.com/originalPosts/66445c839e2e9fda028e9aa2#:~:text=%E6%83%8A%E5%96%9C%E5%9C%A8%E4%BA%8EAI%E5%85%85%E5%88%86%E7%90%86%E8%A7%A3%E4%BA%86%E5%8D%A1%E7%89%87%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%20%E5%B9%B6%E4%BB%8E%E6%95%B4%E4%B8%AA4000%E5%A4%9A%E6%9D%A1%E7%AC%94%E8%AE%B0%E4%B8%AD%E6%89%BE%E5%88%B0%E6%AF%94%E8%BE%83%E7%9B%B8%E5%85%B3%E7%9A%84%EF%BC%8C%20%E8%80%8C%E4%B8%94%E6%98%AF%E3%80%8C%E8%AF%AD%E4%B9%89%E3%80%8D%E7%BA%A7%E5%88%AB%E7%9A%84%E7%9B%B8%E5%85%B3%EF%BC%81%20%E5%8F%A6%E5%A4%96%EF%BC%8C%E6%8E%A8%E8%8D%90%E7%9A%84%E5%8D%A1%E7%89%87%E4%B8%8D%E5%8F%AA%E6%98%AF%E3%80%8C%E7%9B%B8%E5%85%B3%E3%80%8D%EF%BC%8C%20%E8%80%8C%E6%98%AF%E8%83%BD%E3%80%8C%E6%89%93%E5%BC%80%E6%80%9D%E8%B7%AF%E3%80%8D%EF%BC%8C%E9%A1%BA%E7%9D%80%E5%B0%B1%E8%83%BD%E4%BA%A7%E7%94%9F%E6%80%9D%E8%80%83%EF%BC%8C,%E8%BF%99%E5%AF%B9%E4%BA%8E%E5%86%99%E4%BD%9C%E5%92%8C%E6%BF%80%E5%8F%91%E6%80%9D%E8%80%83%E6%9D%A5%E8%AF%B4%E9%9D%9E%E5%B8%B8%E9%87%8D%E8%A6%81%E3%80%82))。

> **例证**：在实践中，有用户反馈 _“AI 充分理解了卡片的内容，并从我4000多条笔记中找出了语义级别相关的笔记”_ ([刚上手flomo的「相关笔记」功能， 连续体验了好几个，超出 - 即刻App](https://m.okjike.com/originalPosts/66445c839e2e9fda028e9aa2#:~:text=%E6%83%8A%E5%96%9C%E5%9C%A8%E4%BA%8EAI%E5%85%85%E5%88%86%E7%90%86%E8%A7%A3%E4%BA%86%E5%8D%A1%E7%89%87%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%20%E5%B9%B6%E4%BB%8E%E6%95%B4%E4%B8%AA4000%E5%A4%9A%E6%9D%A1%E7%AC%94%E8%AE%B0%E4%B8%AD%E6%89%BE%E5%88%B0%E6%AF%94%E8%BE%83%E7%9B%B8%E5%85%B3%E7%9A%84%EF%BC%8C%20%E8%80%8C%E4%B8%94%E6%98%AF%E3%80%8C%E8%AF%AD%E4%B9%89%E3%80%8D%E7%BA%A7%E5%88%AB%E7%9A%84%E7%9B%B8%E5%85%B3%EF%BC%81%20%E5%8F%A6%E5%A4%96%EF%BC%8C%E6%8E%A8%E8%8D%90%E7%9A%84%E5%8D%A1%E7%89%87%E4%B8%8D%E5%8F%AA%E6%98%AF%E3%80%8C%E7%9B%B8%E5%85%B3%E3%80%8D%EF%BC%8C%20%E8%80%8C%E6%98%AF%E8%83%BD%E3%80%8C%E6%89%93%E5%BC%80%E6%80%9D%E8%B7%AF%E3%80%8D%EF%BC%8C%E9%A1%BA%E7%9D%80%E5%B0%B1%E8%83%BD%E4%BA%A7%E7%94%9F%E6%80%9D%E8%80%83%EF%BC%8C,%E8%BF%99%E5%AF%B9%E4%BA%8E%E5%86%99%E4%BD%9C%E5%92%8C%E6%BF%80%E5%8F%91%E6%80%9D%E8%80%83%E6%9D%A5%E8%AF%B4%E9%9D%9E%E5%B8%B8%E9%87%8D%E8%A6%81%E3%80%82))。这表明 Flomo 的向量化方案确实实现了对笔记**语义内容**的把握，而非仅靠标签或字面关键词匹配。

## 相似度计算方式：利用向量间距离衡量相关性

**计算笔记间相关性**：一旦每条笔记都有了向量表示，Flomo 就通过计算向量间的相似度来找到相关笔记。常用的度量方式是**余弦相似度**，即计算两个向量夹角的余弦值来衡量其方向的一致性 ([How to Create a Vector-Based Recommendation System](https://www.e2enetworks.com/blog/how-to-create-a-vector-based-recommendation-system#:~:text=calculate%20the%20similarity%20between%20them,You%20can%20also%20incorporate%20user))。余弦相似度在文本向量比较中非常常见，因为它关注向量方向而忽略长度，适合衡量语义相似度。 ([How to Create a Vector-Based Recommendation System](https://www.e2enetworks.com/blog/how-to-create-a-vector-based-recommendation-system#:~:text=calculate%20the%20similarity%20between%20them,You%20can%20also%20incorporate%20user))。如果两个笔记的向量在高维空间中几乎平行（夹角接近0度），说明它们语义内容相近，余弦相似度接近1；如果夹角较大，相似度就低。另一种等价方法是将向量归一化后计算**欧几里得距离**或点积，但本质上也与余弦相似度一致。综上，**Flomo 很可能采用余弦相似度**来计算笔记向量之间的相似性，从而筛选出最相关的几条笔记。

**技术实现**：在实现上，Flomo 可能会预先计算并存储用户所有笔记的向量表示。当用户查看一条笔记时，系统计算该笔记向量与用户笔记库中其他向量的相似度，取最高的若干条作为“相关笔记”推荐。由于每位用户自己的笔记数量相对有限（几千条级别），在后台用向量检索技术（如近似最近邻算法）实时找到相近向量是可行的。向量相似检索可使用现成的**向量数据库**或算法（如 HNSW、Faiss 等）高效完成，对用户来说这一切都是在毫秒级完成的，保证体验流畅。

## 用户体验上的体现

**自动推荐关联笔记**：在 Flomo 前端，当用户**浏览某条笔记详情**、使用搜索或回顾功能时，界面会自动显示若干条“相关笔记”推荐 ( [相关笔记 ᴾᴿᴼ | flomo 101](https://help.flomoapp.com/basic/xgbj.html#:~:text=,opens%20new%20window))。这些关联笔记被认为与当前笔记内容**联系最紧密**，无需用户手动添加链接。Flomo 官方文档指出：“当你浏览、搜索或回顾 MEMO 时，相关笔记将从你的 flomo 中筛选出与当前 MEMO 最有关的内容，推荐给你” ( [相关笔记 ᴾᴿᴼ | flomo 101](https://help.flomoapp.com/basic/xgbj.html#:~:text=,opens%20new%20window))。也就是说，系统自动帮用户**找出了内容上最相关的笔记**，哪怕它们原本分属不同标签或分类。

**提升知识发现效率**：这一功能在用户体验上带来了两个显著好处：其一，**减轻了用户整理笔记的负担**。用户不再需要像传统卡片笔记法那样手动建立索引、双向链接，AI 会自动“帮你串联卡片” ([刚上手flomo的「相关笔记」功能， 连续体验了好几个，超出 - 即刻App](https://m.okjike.com/originalPosts/66445c839e2e9fda028e9aa2#:~:text=%E5%BE%88%E6%97%A9%40%E5%B0%91%E6%A5%A0Plidezus%20%E5%92%8C%E6%88%91%E8%AF%B4%E8%BF%99%E4%B8%AA%E5%8A%9F%E8%83%BD%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%20%E6%88%91%E5%B0%B1%E6%8A%8A%E6%89%80%E6%9C%89%E9%87%8D%E8%A6%81%E7%9A%84%E7%AC%94%E8%AE%B0%E9%83%BD%E5%AD%98%E5%88%B0flomo%E9%87%8C%E4%BA%86%EF%BC%8C%20%E5%B0%B1%E6%9C%9F%E5%BE%85%E6%9C%89%E8%BF%99%E4%B8%80%E5%A4%A9%EF%BC%8C%E5%BE%88%E5%BC%80%E5%BF%83%E3%80%82))。其二，**激发联想和灵感**。由于推荐的是语义相关的笔记，往往能给用户带来新的启发。“相关笔记”功能的早期体验者反馈说，推荐的卡片**不仅相关，而且能打开思路**，顺着它们可以引发新的思考，对写作和创意很有帮助 ([刚上手flomo的「相关笔记」功能， 连续体验了好几个，超出 - 即刻App](https://m.okjike.com/originalPosts/66445c839e2e9fda028e9aa2#:~:text=%E6%83%8A%E5%96%9C%E5%9C%A8%E4%BA%8EAI%E5%85%85%E5%88%86%E7%90%86%E8%A7%A3%E4%BA%86%E5%8D%A1%E7%89%87%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%20%E5%B9%B6%E4%BB%8E%E6%95%B4%E4%B8%AA4000%E5%A4%9A%E6%9D%A1%E7%AC%94%E8%AE%B0%E4%B8%AD%E6%89%BE%E5%88%B0%E6%AF%94%E8%BE%83%E7%9B%B8%E5%85%B3%E7%9A%84%EF%BC%8C%20%E8%80%8C%E4%B8%94%E6%98%AF%E3%80%8C%E8%AF%AD%E4%B9%89%E3%80%8D%E7%BA%A7%E5%88%AB%E7%9A%84%E7%9B%B8%E5%85%B3%EF%BC%81%20%E5%8F%A6%E5%A4%96%EF%BC%8C%E6%8E%A8%E8%8D%90%E7%9A%84%E5%8D%A1%E7%89%87%E4%B8%8D%E5%8F%AA%E6%98%AF%E3%80%8C%E7%9B%B8%E5%85%B3%E3%80%8D%EF%BC%8C%20%E8%80%8C%E6%98%AF%E8%83%BD%E3%80%8C%E6%89%93%E5%BC%80%E6%80%9D%E8%B7%AF%E3%80%8D%EF%BC%8C%E9%A1%BA%E7%9D%80%E5%B0%B1%E8%83%BD%E4%BA%A7%E7%94%9F%E6%80%9D%E8%80%83%EF%BC%8C,%E8%BF%99%E5%AF%B9%E4%BA%8E%E5%86%99%E4%BD%9C%E5%92%8C%E6%BF%80%E5%8F%91%E6%80%9D%E8%80%83%E6%9D%A5%E8%AF%B4%E9%9D%9E%E5%B8%B8%E9%87%8D%E8%A6%81%E3%80%82))。这表明 Flomo 把用户过去遗忘的想法碎片重新挖掘出来，在需要时呈现给用户，形成了类似“和自己的卡片盒对话”的体验 ([刚上手flomo的「相关笔记」功能， 连续体验了好几个，超出 - 即刻App](https://m.okjike.com/originalPosts/66445c839e2e9fda028e9aa2#:~:text=%E6%9C%80%E6%97%A9%E4%BA%86%E8%A7%A3Zettelkasten%20%E5%B0%B1%E5%BE%88%E5%90%91%E5%BE%80%E5%8D%A2%E6%9B%BC%E8%AF%B4%E7%9A%84%EF%BC%8C%20%E5%8F%AF%E4%BB%A5%E3%80%8C%E5%92%8C%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%A1%E7%89%87%E7%9B%92%E5%AD%90%E5%AF%B9%E8%AF%9D%E3%80%8D%EF%BC%8C%E8%BF%99%E9%9C%80%E8%A6%81%E6%9C%89%E9%99%8C%E7%94%9F%E6%84%9F%EF%BC%8C%20%E5%8D%A2%E6%9B%BC%E4%B8%BA%E8%BF%99%E4%BB%B6%E4%BA%8B%E8%8A%B1%E4%BA%8620%E5%A4%9A%E5%B9%B4%E8%80%8C%E4%B8%94%E6%98%AF%E9%AB%98%E5%BC%BA%E5%BA%A6%E4%BD%BF%E7%94%A8%EF%BC%8C))。

**使用细节**：目前“相关笔记”是 Flomo 的高级功能，需订阅 Pro 会员才能使用 ( [相关笔记 ᴾᴿᴼ | flomo 101](https://help.flomoapp.com/basic/xgbj.html#:~:text=))。在关联笔记列表中，Flomo 还提供了一些实用选项，例如**“隐藏相同标签”**筛选 ( [相关笔记 ᴾᴿᴼ | flomo 101](https://help.flomoapp.com/basic/xgbj.html#:~:text=match%20at%20L110%20%E8%BF%9B%E5%85%A5%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0%E9%A1%B5%E9%9D%A2%E5%90%8E%EF%BC%8C%E7%82%B9%E5%87%BB%E5%8F%B3%E4%B8%8A%E8%A7%92%E2%80%A6%E8%8F%9C%E5%8D%95))。这一选项可以让用户排除那些已经有相同标签（主题明显相同）的笔记，进一步**发掘意料之外的关联**。总体而言，Flomo 将向量化的强大能力隐藏在简洁界面背后，用户只需浏览笔记就能享受智能推荐带来的价值 —— **更轻松地回顾旧笔记、发现知识联系**，把重复机械的整理工作交给AI，专注于思考本身 ([對話flomo少楠：當然會對AI感到恐慌，但別著急 - 新浪香港](https://portal.sina.com.hk/technology/sina/2024/12/03/1064617/%E5%B0%8D%E8%A9%B1flomo%E5%B0%91%E6%A5%A0%EF%BC%9A%E7%95%B6%E7%84%B6%E6%9C%83%E5%B0%8Dai%E6%84%9F%E5%88%B0%E6%81%90%E6%85%8C%EF%BC%8C%E4%BD%86%E5%88%A5%E8%91%97%E6%80%A5/#:~:text=%E5%90%8C%E6%A8%A3%E7%9A%84%E9%81%93%E7%90%86%EF%BC%8C%E6%AF%94%E5%A6%82%E6%88%91%E5%80%91%E4%B9%8B%E5%89%8D%E6%8F%90%E5%88%B0%E7%9A%84%E5%8D%A1%E7%89%87%E7%AD%86%E8%A8%98%E6%B3%95%EF%BC%8C%E9%81%8E%E5%8E%BB%E5%83%8F%E7%9B%A7%E6%9B%BC%E9%82%A3%E6%A8%A3%EF%BC%8C%E6%AF%8F%E5%BC%B5%E5%8D%A1%E7%89%87%E9%83%BD%E8%A6%81%E6%89%8B%E5%AF%AB%E7%B7%A8%E7%A2%BC%EF%BC%8C%E7%84%B6%E5%BE%8C%E8%87%AA%E5%B7%B1%E6%95%B4%E7%90%86%EF%BC%8C%E6%89%BE%E9%97%9C%E8%81%AF%E7%9A%84%E5%8D%A1%E7%89%87%E8%A6%81%E7%BF%BB%E5%8D%8A%E5%A4%A9%EF%BC%8C%E9%80%99%E5%BE%88%E7%B4%AF%E4%BA%BA%E3%80%82%E4%BD%86%E7%8F%BE%E5%9C%A8%E6%9C%89%E4%BA%86%20AI%20%E5%92%8C%E5%90%91%E9%87%8F%E5%8C%96%E6%8A%80%E8%A1%93%EF%BC%8C%E6%88%91%E5%80%91%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%B8%80%E5%BC%B5%E5%8D%A1%E7%89%87%E4%B8%8A%E6%93%81%E6%9C%89%201000%20%E5%A4%9A%E5%80%8B%E7%B6%AD%E5%BA%A6%EF%BC%8C%E9%80%9A%E9%81%8E%E9%80%99%E4%BA%9B%E7%B6%AD%E5%BA%A6%E8%88%87%E5%8F%A6%E4%B8%80%E5%BC%B5%E5%8D%A1%E7%89%87%E9%80%B2%E8%A1%8C%E9%97%9C%E8%81%AF%EF%BC%8CAI,%E5%8F%AF%E4%BB%A5%E5%B9%AB%E5%8A%A9%E6%88%91%E5%80%91%E7%99%BC%E7%8F%BE%E5%85%A9%E5%BC%B5%E5%8D%A1%E7%89%87%E4%B9%8B%E9%96%93%E7%9A%84%E8%81%AF%E7%B9%AB%EF%BC%8C%E5%95%9F%E7%99%BC%E6%88%91%E5%80%91%E6%80%9D%E8%80%83%E3%80%82%E9%80%99%E6%A8%A3%EF%BC%8C%E6%88%91%E5%80%91%E5%B0%B1%E5%8F%AF%E4%BB%A5%E6%8A%8A%E7%BF%BB%E6%89%BE%E5%8D%A1%E7%89%87%E7%9A%84%E9%81%8E%E7%A8%8B%E7%9C%81%E7%95%A5%E6%8E%89%EF%BC%8C%E7%95%99%E5%87%BA%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%99%82%E9%96%93%E5%8E%BB%E5%81%9A%E6%9B%B4%E9%87%8D%E8%A6%81%E7%9A%84%E4%BA%8B%E6%83%85%E3%80%82))。

> **小结**：Flomo 的做法证明了向量化技术在个人笔记管理中的价值。正如少楠所说，向量化属于比较成熟、不会被淘汰的技术 ([對話flomo少楠：當然會對AI感到恐慌，但別著急 - 新浪香港](https://portal.sina.com.hk/technology/sina/2024/12/03/1064617/%E5%B0%8D%E8%A9%B1flomo%E5%B0%91%E6%A5%A0%EF%BC%9A%E7%95%B6%E7%84%B6%E6%9C%83%E5%B0%8Dai%E6%84%9F%E5%88%B0%E6%81%90%E6%85%8C%EF%BC%8C%E4%BD%86%E5%88%A5%E8%91%97%E6%80%A5/#:~:text=AI%20%E7%8F%BE%E5%9C%A8%E9%82%84%E8%99%95%E5%9C%A8%E8%A7%80%E5%AF%9F%E6%9C%9F%EF%BC%8C%E4%B8%80%E6%96%B9%E9%9D%A2%E6%98%AF%E7%A9%8D%E6%A5%B5%E7%90%86%E8%A7%A3%E6%8A%80%E8%A1%93%E7%9A%84%E9%82%8A%E7%95%8C%EF%BC%8C%E5%8F%A6%E4%B8%80%E6%96%B9%E9%9D%A2%E6%98%AF%E6%89%BE%E5%88%B0%E6%8A%80%E8%A1%93%E4%B8%AD%E6%AF%94%E8%BC%83%E6%88%90%E7%86%9F%E7%9A%84%E9%83%A8%E5%88%86%EF%BC%8C%E6%AF%94%E5%A6%82%E5%90%91%E9%87%8F%E5%8C%96%E6%8A%80%E8%A1%93%EF%BC%8C%E9%80%99%E6%98%AF%E5%9F%BA%E7%A4%8E%EF%BC%8C%E4%B8%8D%E6%9C%83%E8%A2%AB%E6%B7%98%E6%B1%B0%E3%80%82%E8%80%8C%E5%B0%8D%E6%96%BC%E4%B8%80%E4%BA%9B%E6%9B%B4%E9%AB%98%E7%B4%9A%E7%9A%84%E6%8A%80%E8%A1%93%EF%BC%8C%E6%AF%94%E5%A6%82%E6%A8%A1%E5%9E%8B%E7%9A%84%20%E8%BF%AD%E4%BB%A3%EF%BC%8C%E6%88%91%E5%80%91%E6%9C%83%E9%81%B8%E6%93%87%E5%86%8D%E8%A7%80%E5%AF%9F%E4%B8%80%E6%AE%B5%E6%99%82%E9%96%93%E3%80%82))。通过语义向量和余弦相似度，Flomo 实现了对用户碎片笔记的**语义关联**和智能推荐，大幅提升了笔记的可用性和可发现性。

# 知识星球中向量化技术的应用可能性

接下来，我们分析**类似的向量化技术在知识星球（ZSXQ）中的应用前景**。知识星球是一个内容社群平台，创作者（星主）在其中发布付费内容或答疑，汇聚了大量主题各异的**帖子和问答**。目前知识星球主要通过人工运营和简单策略来推荐内容，例如针对新用户提供发现页，展示精选内容、星球榜单等，以吸引用户加入热门星球 ([知识星球产品分析报告：付费知识困局下如何破局 | 人人都是产品经理](https://www.woshipm.com/evaluating/3314634.html#:~:text=%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83%E5%B9%B3%E5%8F%B0%E4%B8%8A%E4%B9%9F%E5%BC%80%E8%AE%BE%E4%BA%86%E5%8F%91%E7%8E%B0%E9%A1%B5%E9%9D%A2%EF%BC%8C%E9%80%9A%E8%BF%87%E5%90%91%E6%96%B0%E7%94%A8%E6%88%B7%E5%B1%95%E7%A4%BA%E7%B2%BE%E5%8D%8E%E5%86%85%E5%AE%B9%EF%BC%8C%E6%8E%A8%E8%8D%90%E6%98%9F%E7%90%83%EF%BC%8C%E5%B1%95%E7%A4%BA%E6%98%9F%E7%90%83%E6%A6%9C%E5%8D%95%E7%AD%89%E6%96%B9%E5%BC%8F%EF%BC%8C%E5%B8%AE%E5%8A%A9%E6%98%9F%E4%B8%BB%E6%8B%89%E6%96%B0%E5%92%8C%E8%BD%AC%E5%8C%96%E3%80%82))。这种方式更多依赖于内容热度和人工筛选。若引入**文本向量化与相似度计算**，则有望实现更智能的内容推荐、关联和用户兴趣匹配，提升用户体验和平台价值。下面从内容结构、推荐关联、兴趣匹配和实现思路四方面展开分析。

## 内容结构与向量化的适配

**内容单元的向量表示**：知识星球的主要内容单元包括星主发布的文章帖子、付费问答以及用户评论等。这些都以文本为主（可能包含图片、链接等辅助信息）。可以将每个**帖子或问答**视作一段文本内容，通过与 Flomo 类似的方式转化为语义向量。例如，使用预训练的中文句向量模型（如中文 **BERT/ERNIE**、SimCSE 或开源的 **Chinese Sentence Transformers**）将帖子标题+正文Embedding成一个向量。对于问答帖，可以将**问题和回答内容拼接**后向量化，捕捉其完整语义。每条内容就此拥有了可用于比较的向量表示。

**结构信息的利用**：知识星球的内容往往还带有**元数据**，如话题标签、发表时间、点赞数等。其中标签等结构化信息也可结合向量表示一起利用。例如，某些星球已经支持给帖子打标签分类 ([星球功能| 知识星球· 知识库](https://doc.zsxq.com/newuser/features.html#:~:text=%E6%98%9F%E7%90%83%E5%8A%9F%E8%83%BD,%C2%B7%20%E5%A6%82%E4%BD%95%E5%9C%A8App%20%E7%AB%AF%E8%87%AA%E5%AE%9A%E4%B9%89%E3%80%8C%E4%B8%AA%E4%BA%BA%E4%BB%8B%E7%BB%8D%E3%80%8D))。在向量检索时，可以将标签作为过滤或加权因素：优先在相同主题标签内寻找相似内容，或反之排除掉标签完全相同的内容以发现跨领域联系（类似 Flomo 提供的“隐藏相同标签”选项）。另外，每个星球社群本身有主题定位，可将**星球ID**视作内容属性，在做全局推荐时确保只推荐用户有权限查看或感兴趣的星球内的内容。

**长度与多模态**：知识星球的帖子长度可能不一，从短问答到长文章都有。向量模型对长度并不严格限制，但**长文**可考虑截断或分段向量化然后平均/聚合，以免超出模型输入长度。对于附带的**图片或文件**，如果需要深入分析，也可以使用图像向量化模型生成图像嵌入，再与文本向量结合（这属于拓展方向，本文以文本为主）。总体而言，知识星球的内容大多是**非结构化文本**，这与 Flomo 的笔记非常类似，完全可以适配**向量化表示**。

## 向量化助力内容推荐与关联

引入向量化后，知识星球可以大幅强化**内容分发和关联推荐**：

- **语义内容推荐**：目前平台的发现页主要推荐**热门星球**和人工精选内容 ([知识星球产品分析报告：付费知识困局下如何破局 | 人人都是产品经理](https://www.woshipm.com/evaluating/3314634.html#:~:text=%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83%E5%B9%B3%E5%8F%B0%E4%B8%8A%E4%B9%9F%E5%BC%80%E8%AE%BE%E4%BA%86%E5%8F%91%E7%8E%B0%E9%A1%B5%E9%9D%A2%EF%BC%8C%E9%80%9A%E8%BF%87%E5%90%91%E6%96%B0%E7%94%A8%E6%88%B7%E5%B1%95%E7%A4%BA%E7%B2%BE%E5%8D%8E%E5%86%85%E5%AE%B9%EF%BC%8C%E6%8E%A8%E8%8D%90%E6%98%9F%E7%90%83%EF%BC%8C%E5%B1%95%E7%A4%BA%E6%98%9F%E7%90%83%E6%A6%9C%E5%8D%95%E7%AD%89%E6%96%B9%E5%BC%8F%EF%BC%8C%E5%B8%AE%E5%8A%A9%E6%98%9F%E4%B8%BB%E6%8B%89%E6%96%B0%E5%92%8C%E8%BD%AC%E5%8C%96%E3%80%82))。通过向量化，可实现**基于内容的推荐**：当用户浏览某帖子时，系统可以实时计算该帖的向量，与平台中其他内容向量比较，找到**语义相似**的帖子推荐给用户。这些推荐可以来自**同一星球**（便于用户纵向深入相关话题），也可以在**全平台**范围内寻找相似主题的公开内容。如果用户尚未加入那些星球，可以适当展示部分内容摘要，提示“你可能对某星球的相关讨论感兴趣”，引导其加入。这样的推荐依据内容本身的相似度，而非仅仅根据浏览量或人工推荐，能够发现**长尾内容和小众兴趣**，让每个用户都看到契合自己喜好的帖子。
    
- **相关帖子/问答串联**：类似 Flomo 的相关笔记，知识星球内也可实现**相关内容关联**。当用户打开某个帖子或问答时，在页面下方显示**“相关讨论”**列表。例如，“问题A”的页面下自动列出以前可能问过的类似问题或相关主题的讨论帖。因为采用语义匹配，即使措辞不同的问题，只要主题相近（比如不同用户提问了相似的技术疑惑），系统就能识别并列出对应帖子 ([What are Vector Embeddings | Pinecone](https://www.pinecone.io/learn/vector-embeddings/#:~:text=In%20other%20words%2C%20when%20we,as%20clustering%2C%20recommendation%2C%20and%20classification))。这有助于减少重复提问和内容冗余——新提问的用户可以很快看到过去的相关解答，星主也不必一再回答相同问题。对于长期积累的星球内容，新的成员也能通过相关帖推荐**快速挖掘历史讨论**精华。
    
- **跨内容类型的关联**：向量化还支持跨越不同内容形式的关联。例如，可以将**星主的文章和问答**放在一起比较，只要话题相关也能互相推荐。用户在看星主的一篇教程文章时，相关内容栏里不仅有本星球其他文章，还有可能列出几条Q&A问答，这些问答恰好对应文章涉及的概念疑问。这种跨内容的关联由语义驱动，弥补了人工分类的不足，帮助用户从多个角度了解同一主题。
    

值得注意的是，这些**语义推荐**不会局限于表面关键词匹配，而是真正基于内容含义的接近 ([刚上手flomo的「相关笔记」功能， 连续体验了好几个，超出 - 即刻App](https://m.okjike.com/originalPosts/66445c839e2e9fda028e9aa2#:~:text=%E6%83%8A%E5%96%9C%E5%9C%A8%E4%BA%8EAI%E5%85%85%E5%88%86%E7%90%86%E8%A7%A3%E4%BA%86%E5%8D%A1%E7%89%87%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%20%E5%B9%B6%E4%BB%8E%E6%95%B4%E4%B8%AA4000%E5%A4%9A%E6%9D%A1%E7%AC%94%E8%AE%B0%E4%B8%AD%E6%89%BE%E5%88%B0%E6%AF%94%E8%BE%83%E7%9B%B8%E5%85%B3%E7%9A%84%EF%BC%8C%20%E8%80%8C%E4%B8%94%E6%98%AF%E3%80%8C%E8%AF%AD%E4%B9%89%E3%80%8D%E7%BA%A7%E5%88%AB%E7%9A%84%E7%9B%B8%E5%85%B3%EF%BC%81%20%E5%8F%A6%E5%A4%96%EF%BC%8C%E6%8E%A8%E8%8D%90%E7%9A%84%E5%8D%A1%E7%89%87%E4%B8%8D%E5%8F%AA%E6%98%AF%E3%80%8C%E7%9B%B8%E5%85%B3%E3%80%8D%EF%BC%8C%20%E8%80%8C%E6%98%AF%E8%83%BD%E3%80%8C%E6%89%93%E5%BC%80%E6%80%9D%E8%B7%AF%E3%80%8D%EF%BC%8C%E9%A1%BA%E7%9D%80%E5%B0%B1%E8%83%BD%E4%BA%A7%E7%94%9F%E6%80%9D%E8%80%83%EF%BC%8C,%E8%BF%99%E5%AF%B9%E4%BA%8E%E5%86%99%E4%BD%9C%E5%92%8C%E6%BF%80%E5%8F%91%E6%80%9D%E8%80%83%E6%9D%A5%E8%AF%B4%E9%9D%9E%E5%B8%B8%E9%87%8D%E8%A6%81%E3%80%82))。因此可以发现一些**意想不到的联系**：例如某帖子的主题“职场心理”可能会关联到另一星球里关于“效率与情绪管理”的讨论，虽表面词不同但核心思想相通。这种发现有利于用户拓展知识广度，在平台内形成**知识网络**。

## 用户兴趣匹配与个性化

通过向量化，知识星球可以更精准地刻画**用户兴趣画像**，从而实现**个性化推荐**和匹配：

- **用户向量画像**：可以为每个用户构建一个或多个**兴趣向量**。做法是汇总用户在平台上的行为：例如TA发表或评论的内容向量、点赞收藏过的帖子向量，甚至TA加入的星球简介向量，都可以纳入考虑。通过对这些向量求平均或加权叠加，得到用户在语义空间中的偏好分布。比如某用户的笔记/发言多与“机器学习”相关，则其兴趣向量在“AI技术”维度上会有较高权重。
    
- **星球主题向量**：同理，可以为每个**星球**计算一个**主题向量**，代表该社群的主要内容方向。可将该星球历史帖子向量取平均，或抽取星球公告、简介和高赞帖子的向量综合形成代表性向量。这一向量相当于星球在语义空间中的“坐标”。
    
- **匹配与推荐**：有了用户向量和星球向量，就可以计算两者的相似度，做**星球推荐**：匹配度高的说明该用户可能对那个星球感兴趣。例如，如果某用户经常关注理财投资类内容，而平台上有个星球主题也是投资理财，那么两者向量在语义上会接近，系统即可在发现页里向该用户**个性化推荐**这个星球（而不仅仅是因为它上了总排行榜）。目前发现页主要依赖总体热门榜单 ([知识星球产品分析报告：付费知识困局下如何破局 | 人人都是产品经理](https://www.woshipm.com/evaluating/3314634.html#:~:text=%E5%8F%91%E7%8E%B0%E9%A1%B5%E9%9D%A2%EF%BC%8C%E8%87%AA%E5%8A%A8%E6%8E%A8%E8%8D%90%E6%98%9F%E7%90%83%E5%92%8C%E7%B2%BE%E5%8D%8E%E5%86%85%E5%AE%B9%EF%BC%8C%E5%90%B8%E5%BC%95%E6%96%B0%E7%94%A8%E6%88%B7%E4%BA%86%E8%A7%A3%E8%BF%99%E9%83%A8%E5%88%86%E6%98%9F%E7%90%83%E5%B9%B6%E4%B8%94%E5%8A%A0%E5%85%A5%E3%80%82%E9%80%9A%E8%BF%87%E8%B4%A2%E5%AF%8C%E6%A6%9C%E5%92%8C%E6%B4%BB%E8%B7%83%E6%A6%9C%E7%9A%84%E5%B1%95%E7%A4%BA%E5%BD%A2%E5%BC%8F%E6%9D%A5%E5%90%B8%E5%BC%95%E7%94%A8%E6%88%B7%E5%8A%A0%E5%85%A5%E6%98%9F%E7%90%83%E4%B8%AD%E3%80%82))，加入这种**向量匹配推荐**后，每位用户都会看到更贴合自己兴趣的星球列表。
    
- **内容订阅和通知**：进一步地，向量化还能用于细化用户订阅偏好。例如用户在某收费星球内特别关注“Python 编程”方面的话题，那么他的兴趣向量中该主题维度很高。系统可据此在该星球有新的相关帖子发布时主动通知该用户，提高用户黏性和内容触达率。这种**兴趣匹配**是在语义层次进行的，比仅靠标签订阅更智能：即使帖子没有打明确标签，但其内容语义符合用户画像，也会被匹配出来提醒用户。
    
- **社群关系挖掘**：在更宏观层面，所有用户的向量可以聚类，找到相似兴趣的用户群体；所有星球向量也能聚类，划分出内容相近的星球类别。这些对运营也有指导意义，例如发现某冷门领域其实聚集了一批忠实用户，平台可以考虑重点运营相关话题或策划活动。用户之间的匹配（例如结识志同道合者）也有可能通过向量相似度实现，不过需要考虑隐私和产品定位（知识星球更强调内容付费社区，社交可能不是主要诉求）。
    

总之，向量化为**用户和内容**都赋予了可计算的语义特征向量，使得平台可以做到**千人千面**的推荐和匹配。正如业界所认识到的，向量表示让机器能够量化“语义相似度”，把人类感知的相近概念转化为向量空间中的距离 ([What are Vector Embeddings | Pinecone](https://www.pinecone.io/learn/vector-embeddings/#:~:text=In%20other%20words%2C%20when%20we,as%20clustering%2C%20recommendation%2C%20and%20classification))。借此，知识星球能够跳出简单的基于浏览历史或热门度的推荐，用更深入的**内容理解**来连接用户和知识。

## 技术实现思路

要在知识星球中落地上述向量化应用，需要考虑**模型选型、数据流程和系统性能**等方面：

- **选择向量化模型**：应优先采用适合中文短文本的预训练模型。例如**中文 BERT** 或 **RoBERTa** 经过对句子聚类任务微调的版本（类似 SimCSE），能输出效果较好的句向量。也可以考虑开源的**Sentence-BERT 多语种模型**，或商用 API（如 OpenAI Embedding）等。但需权衡精度与效率，最好是**离线部署**的模型以保护数据隐私和降低长期成本。输出向量维度在数百维量级即可满足需求（如 512 或 768 维），维度过高虽提升表示能力但也增加计算开销。
    
- **构建向量索引**：将模型应用于**历史内容批量向量化**，建立向量索引库。对于**每个星球内部**的内容关联，可以按星球分别存储向量列表，在星球内做小规模相似检索。对于**跨星球**的推荐（如推荐星球给用户），需要建立全局的索引（如所有星球向量的索引，或热门帖子向量索引）。可以使用高效的**近似最近邻（ANN）算法**来支持百万级向量的快速相似搜索 ([RAG等业务中，如何完成亿级向量的快速检索？_rag 推荐 - CSDN博客](https://blog.csdn.net/m0_59235945/article/details/145041854#:~:text=RAG%E7%AD%89%E4%B8%9A%E5%8A%A1%E4%B8%AD%EF%BC%8C%E5%A6%82%E4%BD%95%E5%AE%8C%E6%88%90%E4%BA%BF%E7%BA%A7%E5%90%91%E9%87%8F%E7%9A%84%E5%BF%AB%E9%80%9F%E6%A3%80%E7%B4%A2%EF%BC%9F_rag%20%E6%8E%A8%E8%8D%90%20,%EF%BC%8C%E6%9C%80%E5%B8%B8%E7%94%A8%E7%9A%84%E6%96%B9%E6%B3%95%E5%B0%B1%E6%98%AF%E7%94%A8%E6%88%B7Query%E5%90%91%E9%87%8F%E4%B8%8E%E5%90%91%E9%87%8F%E5%BA%93%E4%B8%AD%E7%9A%84%E6%AF%8F%E4%B8%AA%E5%90%91%E9%87%8F%E9%81%8D%E5%8E%86%E6%A3%80%E7%B4%A2%E5%BE%97%E5%88%B0%E7%AD%94%E6%A1%88%EF%BC%8C%E4%BF%97%E7%A7%B0%E6%9A%B4%E5%8A%9B))。常用的实现如 **Faiss** 库、**HNSWlib**（基于图的近邻搜索）或专门的向量数据库如 **Milvus、Pinecone** 等。这些工具被设计来在向量库中快速找出与查询向量距离最近的项，典型查询时间可以控制在几十毫秒内，即使向量库规模很大。
    
- **在线更新机制**：知识星球是动态社区，新内容不断产生，因此向量索引需要**实时或定期更新**。可采用**增量更新**策略：当有新帖子发布时，立即计算其向量并加入索引；对于已有内容的编辑则更新向量。用户画像向量也可定期随用户行为变化重新计算（例如每天更新一次或实时微调）。为了效率，计算向量时可以使用**GPU 加速**或批处理。如用户量和内容量巨大，需部署**分布式向量服务**来支撑高并发查询和更新。
    
- **相似度阈值和结果过滤**：实际应用中，可能需要设置**相似度阈值**来过滤结果，避免推荐一些仅有微弱相关性的内容。此外，可以结合**业务规则**：例如跨星球推荐时，只推荐那些公开星球或用户尚未加入的星球；在星球内关联时，避免推送同一作者的过于相似的多篇内容以增加多样性等。向量结果也可与**协同过滤**（基于用户行为的推荐）结合，形成混合推荐，提高准确性 ([How to Create a Vector-Based Recommendation System](https://www.e2enetworks.com/blog/how-to-create-a-vector-based-recommendation-system#:~:text=1,the%20similarity%20between%20these%20vectors)) ([How to Create a Vector-Based Recommendation System](https://www.e2enetworks.com/blog/how-to-create-a-vector-based-recommendation-system#:~:text=ratings,vectors%20in%20the%20embedded%20space))。协同过滤善于根据用户喜好模式推荐，向量语义善于找内容相似项，两者结合能取长补短。
    
- **性能和扩展**：为了不影响用户体验，相关计算应该做到**尽可能异步或预计算**。例如，可以提前为每个帖子准备好若干相似帖列表缓存，当用户访问时直接读取（定期刷新缓存以跟进新内容）。对于用户星球推荐，同样可为每个用户离线计算匹配度最高的星球列表，或在用户登录时即时计算但控制在可接受范围。借助向量化技术的高效实现（例如利用向量点积的矩阵运算能力），平台完全可以在保证性能的前提下提供这些智能功能。
    

**应用案例展望**：综合来看，在知识星球引入向量化技术是**切实可行且收益明显**的。从 Flomo 的实践经验可以看到，向量化能够**深入挖掘语义关联**、提升内容复用和发现效率 ([刚上手flomo的「相关笔记」功能， 连续体验了好几个，超出 - 即刻App](https://m.okjike.com/originalPosts/66445c839e2e9fda028e9aa2#:~:text=%E6%83%8A%E5%96%9C%E5%9C%A8%E4%BA%8EAI%E5%85%85%E5%88%86%E7%90%86%E8%A7%A3%E4%BA%86%E5%8D%A1%E7%89%87%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%20%E5%B9%B6%E4%BB%8E%E6%95%B4%E4%B8%AA4000%E5%A4%9A%E6%9D%A1%E7%AC%94%E8%AE%B0%E4%B8%AD%E6%89%BE%E5%88%B0%E6%AF%94%E8%BE%83%E7%9B%B8%E5%85%B3%E7%9A%84%EF%BC%8C%20%E8%80%8C%E4%B8%94%E6%98%AF%E3%80%8C%E8%AF%AD%E4%B9%89%E3%80%8D%E7%BA%A7%E5%88%AB%E7%9A%84%E7%9B%B8%E5%85%B3%EF%BC%81%20%E5%8F%A6%E5%A4%96%EF%BC%8C%E6%8E%A8%E8%8D%90%E7%9A%84%E5%8D%A1%E7%89%87%E4%B8%8D%E5%8F%AA%E6%98%AF%E3%80%8C%E7%9B%B8%E5%85%B3%E3%80%8D%EF%BC%8C%20%E8%80%8C%E6%98%AF%E8%83%BD%E3%80%8C%E6%89%93%E5%BC%80%E6%80%9D%E8%B7%AF%E3%80%8D%EF%BC%8C%E9%A1%BA%E7%9D%80%E5%B0%B1%E8%83%BD%E4%BA%A7%E7%94%9F%E6%80%9D%E8%80%83%EF%BC%8C,%E8%BF%99%E5%AF%B9%E4%BA%8E%E5%86%99%E4%BD%9C%E5%92%8C%E6%BF%80%E5%8F%91%E6%80%9D%E8%80%83%E6%9D%A5%E8%AF%B4%E9%9D%9E%E5%B8%B8%E9%87%8D%E8%A6%81%E3%80%82))。对于拥有海量内容和用户的知识星球，这种技术将帮助平台从“广场式的热门推荐”升级为“千人千面的知识服务”。用户将更容易找到自己感兴趣的优质内容和社群，星主的内容也能精准触达目标受众，减少信息噪音。随着大模型和向量数据库技术的发展成熟，**语义向量检索**已成为推荐系统和搜索引擎的重要工具 ([What are Vector Embeddings | Pinecone](https://www.pinecone.io/learn/vector-embeddings/#:~:text=In%20other%20words%2C%20when%20we,as%20clustering%2C%20recommendation%2C%20and%20classification))。可以预见，知识星球等知识付费社区引入向量化后，将大幅增强**内容推荐和知识关联**能力，在满足用户个性化需求的同时，促进社区的活跃与留存。

**参考文献：**

- 【5】 少楠, _对话 flomo 少楠：..._ – _提到借助 AI 向量化，每张卡片拥有1000多维度，并通过这些维度关联笔记_ ([對話flomo少楠：當然會對AI感到恐慌，但別著急 - 新浪香港](https://portal.sina.com.hk/technology/sina/2024/12/03/1064617/%E5%B0%8D%E8%A9%B1flomo%E5%B0%91%E6%A5%A0%EF%BC%9A%E7%95%B6%E7%84%B6%E6%9C%83%E5%B0%8Dai%E6%84%9F%E5%88%B0%E6%81%90%E6%85%8C%EF%BC%8C%E4%BD%86%E5%88%A5%E8%91%97%E6%80%A5/#:~:text=%E5%90%8C%E6%A8%A3%E7%9A%84%E9%81%93%E7%90%86%EF%BC%8C%E6%AF%94%E5%A6%82%E6%88%91%E5%80%91%E4%B9%8B%E5%89%8D%E6%8F%90%E5%88%B0%E7%9A%84%E5%8D%A1%E7%89%87%E7%AD%86%E8%A8%98%E6%B3%95%EF%BC%8C%E9%81%8E%E5%8E%BB%E5%83%8F%E7%9B%A7%E6%9B%BC%E9%82%A3%E6%A8%A3%EF%BC%8C%E6%AF%8F%E5%BC%B5%E5%8D%A1%E7%89%87%E9%83%BD%E8%A6%81%E6%89%8B%E5%AF%AB%E7%B7%A8%E7%A2%BC%EF%BC%8C%E7%84%B6%E5%BE%8C%E8%87%AA%E5%B7%B1%E6%95%B4%E7%90%86%EF%BC%8C%E6%89%BE%E9%97%9C%E8%81%AF%E7%9A%84%E5%8D%A1%E7%89%87%E8%A6%81%E7%BF%BB%E5%8D%8A%E5%A4%A9%EF%BC%8C%E9%80%99%E5%BE%88%E7%B4%AF%E4%BA%BA%E3%80%82%E4%BD%86%E7%8F%BE%E5%9C%A8%E6%9C%89%E4%BA%86%20AI%20%E5%92%8C%E5%90%91%E9%87%8F%E5%8C%96%E6%8A%80%E8%A1%93%EF%BC%8C%E6%88%91%E5%80%91%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%B8%80%E5%BC%B5%E5%8D%A1%E7%89%87%E4%B8%8A%E6%93%81%E6%9C%89%201000%20%E5%A4%9A%E5%80%8B%E7%B6%AD%E5%BA%A6%EF%BC%8C%E9%80%9A%E9%81%8E%E9%80%99%E4%BA%9B%E7%B6%AD%E5%BA%A6%E8%88%87%E5%8F%A6%E4%B8%80%E5%BC%B5%E5%8D%A1%E7%89%87%E9%80%B2%E8%A1%8C%E9%97%9C%E8%81%AF%EF%BC%8CAI,%E5%8F%AF%E4%BB%A5%E5%B9%AB%E5%8A%A9%E6%88%91%E5%80%91%E7%99%BC%E7%8F%BE%E5%85%A9%E5%BC%B5%E5%8D%A1%E7%89%87%E4%B9%8B%E9%96%93%E7%9A%84%E8%81%AF%E7%B9%AB%EF%BC%8C%E5%95%9F%E7%99%BC%E6%88%91%E5%80%91%E6%80%9D%E8%80%83%E3%80%82%E9%80%99%E6%A8%A3%EF%BC%8C%E6%88%91%E5%80%91%E5%B0%B1%E5%8F%AF%E4%BB%A5%E6%8A%8A%E7%BF%BB%E6%89%BE%E5%8D%A1%E7%89%87%E7%9A%84%E9%81%8E%E7%A8%8B%E7%9C%81%E7%95%A5%E6%8E%89%EF%BC%8C%E7%95%99%E5%87%BA%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%99%82%E9%96%93%E5%8E%BB%E5%81%9A%E6%9B%B4%E9%87%8D%E8%A6%81%E7%9A%84%E4%BA%8B%E6%83%85%E3%80%82))
- 【21】 机智的阿饭, _即刻动态_ – _用户反馈flomo相关笔记功能基于语义的关联效果（AI充分理解内容，在4000多条笔记中找到语义级相关）_ ([刚上手flomo的「相关笔记」功能， 连续体验了好几个，超出 - 即刻App](https://m.okjike.com/originalPosts/66445c839e2e9fda028e9aa2#:~:text=%E6%83%8A%E5%96%9C%E5%9C%A8%E4%BA%8EAI%E5%85%85%E5%88%86%E7%90%86%E8%A7%A3%E4%BA%86%E5%8D%A1%E7%89%87%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%20%E5%B9%B6%E4%BB%8E%E6%95%B4%E4%B8%AA4000%E5%A4%9A%E6%9D%A1%E7%AC%94%E8%AE%B0%E4%B8%AD%E6%89%BE%E5%88%B0%E6%AF%94%E8%BE%83%E7%9B%B8%E5%85%B3%E7%9A%84%EF%BC%8C%20%E8%80%8C%E4%B8%94%E6%98%AF%E3%80%8C%E8%AF%AD%E4%B9%89%E3%80%8D%E7%BA%A7%E5%88%AB%E7%9A%84%E7%9B%B8%E5%85%B3%EF%BC%81%20%E5%8F%A6%E5%A4%96%EF%BC%8C%E6%8E%A8%E8%8D%90%E7%9A%84%E5%8D%A1%E7%89%87%E4%B8%8D%E5%8F%AA%E6%98%AF%E3%80%8C%E7%9B%B8%E5%85%B3%E3%80%8D%EF%BC%8C%20%E8%80%8C%E6%98%AF%E8%83%BD%E3%80%8C%E6%89%93%E5%BC%80%E6%80%9D%E8%B7%AF%E3%80%8D%EF%BC%8C%E9%A1%BA%E7%9D%80%E5%B0%B1%E8%83%BD%E4%BA%A7%E7%94%9F%E6%80%9D%E8%80%83%EF%BC%8C,%E8%BF%99%E5%AF%B9%E4%BA%8E%E5%86%99%E4%BD%9C%E5%92%8C%E6%BF%80%E5%8F%91%E6%80%9D%E8%80%83%E6%9D%A5%E8%AF%B4%E9%9D%9E%E5%B8%B8%E9%87%8D%E8%A6%81%E3%80%82))
- 【19】 bylander, _RAG 与推荐系统 - CSDN博客_ – _说明稠密向量检索模型用连续实数向量表示文本，与传统 TF-IDF 稀疏向量的对比_ ([〖AI学习〗RAG与推荐系统_rag 推荐系统-CSDN博客](https://blog.csdn.net/bylander/article/details/138199906#:~:text=%E7%A8%A0%E5%AF%86%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%EF%BC%88Dense%20Retriever%EF%BC%89%E6%98%AF%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%EF%BC%88NLP%EF%BC%89%E5%92%8C%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E9%A2%86%E5%9F%9F%E4%B8%AD%E7%9A%84%E4%B8%80%E4%B8%AA%E6%9C%AF%E8%AF%AD%EF%BC%8C%E5%AE%83%E6%8C%87%E7%9A%84%E6%98%AF%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%AF%86%E9%9B%86%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%E7%9A%84%E6%96%87%E6%A1%A3%E6%A3%80%E7%B4%A2%E6%96%B9%E6%B3%95%E3%80%82%E8%BF%99%E7%A7%8D%E6%A8%A1%E5%9E%8B%E4%B9%8B%E6%89%80%E4%BB%A5%E8%A2%AB%E7%A7%B0%20%E4%B8%BA%E2%80%9C%E7%A8%A0%E5%AF%86%E2%80%9D%EF%BC%88Dense%EF%BC%89%EF%BC%8C%E6%98%AF%E5%9B%A0%E4%B8%BA%E5%AE%83%E4%BB%AC%E4%BD%BF%E7%94%A8%E8%BF%9E%E7%BB%AD%E7%9A%84%E3%80%81%E7%A8%A0%E5%AF%86%E7%9A%84%E5%90%91%E9%87%8F%EF%BC%88%E9%80%9A%E5%B8%B8%E6%98%AF%E5%AE%9E%E6%95%B0%E5%90%91%E9%87%8F%EF%BC%89%E6%9D%A5%E8%A1%A8%E7%A4%BA%E6%9F%A5%E8%AF%A2%EF%BC%88query%EF%BC%89%E5%92%8C%E6%96%87%E6%A1%A3%EF%BC%88document%EF%BC%89%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BC%A0%E7%BB%9F%E7%9A%84%E7%A8%80%E7%96%8F%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%E3%80%82%20%E5%9C%A8%E4%BC%A0%E7%BB%9F%E7%9A%84%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F%E4%B8%AD%EF%BC%8C%E6%96%87%E6%A1%A3%E5%92%8C%E6%9F%A5%E8%AF%A2%E9%80%9A%E5%B8%B8%E6%98%AF%E9%80%9A%E8%BF%87%E7%A8%80%E7%96%8F%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA%E7%9A%84%EF%BC%8C%E4%BE%8B%E5%A6%82%E4%BD%BF%E7%94%A8TF,Words%EF%BC%89%EF%BC%8C%E5%85%B6%E4%B8%AD%E5%90%91%E9%87%8F%E4%B8%AD%E7%9A%84%E6%AF%8F%E4%B8%AA%E5%85%83%E7%B4%A0%E5%AF%B9%E5%BA%94%E4%BA%8E%E8%AF%8D%E6%B1%87%E8%A1%A8%E4%B8%AD%E7%9A%84%E4%B8%80%E4%B8%AA%E5%8D%95%E8%AF%8D%EF%BC%8C%E5%B9%B6%E4%B8%94%E5%8F%AA%E6%9C%89%E5%8D%95%E8%AF%8D%E5%87%BA%E7%8E%B0%E6%97%B6%E5%85%83%E7%B4%A0%E6%89%8D%E9%9D%9E%E9%9B%B6%E3%80%82%20%E7%9B%B8%E6%AF%94%E4%B9%8B%E4%B8%8B%EF%BC%8C%E7%A8%A0%E5%AF%86%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF%EF%BC%8C%E5%A6%82%E5%8F%98%E6%8D%A2%E5%99%A8%EF%BC%88Transformers%EF%BC%89%E6%88%96BERT%EF%BC%88Bidirectional%20Encoder))
- 【16】 flomo 官方文档, _相关笔记 PRO_ – _描述相关笔记功能会筛选当前 MEMO 最有关的内容推荐给你_ ( [相关笔记 ᴾᴿᴼ | flomo 101](https://help.flomoapp.com/basic/xgbj.html#:~:text=,opens%20new%20window))
- 【17】 flomo 官方文档, _相关笔记 PRO_ – _提到可通过筛选隐藏相同标签的笔记，以发现不同标签下相关内容_ ( [相关笔记 ᴾᴿᴼ | flomo 101](https://help.flomoapp.com/basic/xgbj.html#:~:text=%E8%BF%9B%E5%85%A5%E7%9B%B8%E5%85%B3%E7%AC%94%E8%AE%B0%E9%A1%B5%E9%9D%A2%E5%90%8E%EF%BC%8C%E7%82%B9%E5%87%BB%E5%8F%B3%E4%B8%8A%E8%A7%92%E2%80%A6%E8%8F%9C%E5%8D%95))
- 【4】 少楠, _对话 flomo 少楠_ – _指出向量化技术是基础且不会被淘汰的成熟技术_ ([對話flomo少楠：當然會對AI感到恐慌，但別著急 - 新浪香港](https://portal.sina.com.hk/technology/sina/2024/12/03/1064617/%E5%B0%8D%E8%A9%B1flomo%E5%B0%91%E6%A5%A0%EF%BC%9A%E7%95%B6%E7%84%B6%E6%9C%83%E5%B0%8Dai%E6%84%9F%E5%88%B0%E6%81%90%E6%85%8C%EF%BC%8C%E4%BD%86%E5%88%A5%E8%91%97%E6%80%A5/#:~:text=AI%20%E7%8F%BE%E5%9C%A8%E9%82%84%E8%99%95%E5%9C%A8%E8%A7%80%E5%AF%9F%E6%9C%9F%EF%BC%8C%E4%B8%80%E6%96%B9%E9%9D%A2%E6%98%AF%E7%A9%8D%E6%A5%B5%E7%90%86%E8%A7%A3%E6%8A%80%E8%A1%93%E7%9A%84%E9%82%8A%E7%95%8C%EF%BC%8C%E5%8F%A6%E4%B8%80%E6%96%B9%E9%9D%A2%E6%98%AF%E6%89%BE%E5%88%B0%E6%8A%80%E8%A1%93%E4%B8%AD%E6%AF%94%E8%BC%83%E6%88%90%E7%86%9F%E7%9A%84%E9%83%A8%E5%88%86%EF%BC%8C%E6%AF%94%E5%A6%82%E5%90%91%E9%87%8F%E5%8C%96%E6%8A%80%E8%A1%93%EF%BC%8C%E9%80%99%E6%98%AF%E5%9F%BA%E7%A4%8E%EF%BC%8C%E4%B8%8D%E6%9C%83%E8%A2%AB%E6%B7%98%E6%B1%B0%E3%80%82%E8%80%8C%E5%B0%8D%E6%96%BC%E4%B8%80%E4%BA%9B%E6%9B%B4%E9%AB%98%E7%B4%9A%E7%9A%84%E6%8A%80%E8%A1%93%EF%BC%8C%E6%AF%94%E5%A6%82%E6%A8%A1%E5%9E%8B%E7%9A%84%20%E8%BF%AD%E4%BB%A3%EF%BC%8C%E6%88%91%E5%80%91%E6%9C%83%E9%81%B8%E6%93%87%E5%86%8D%E8%A7%80%E5%AF%9F%E4%B8%80%E6%AE%B5%E6%99%82%E9%96%93%E3%80%82))
- 【26】 Hady Khamis Khan, _Vector-Based Recommendation System_ – _说明常用的相似度度量包括余弦相似度，用于计算向量间的相似性_ ([How to Create a Vector-Based Recommendation System](https://www.e2enetworks.com/blog/how-to-create-a-vector-based-recommendation-system#:~:text=calculate%20the%20similarity%20between%20them,You%20can%20also%20incorporate%20user))
- 【31】 人人都是产品经理, _知识星球产品分析报告_ – _提到知识星球的发现页通过展示精选内容和推荐星球来拉新（当前主要基于榜单热门）_ ([知识星球产品分析报告：付费知识困局下如何破局 | 人人都是产品经理](https://www.woshipm.com/evaluating/3314634.html#:~:text=%E7%9F%A5%E8%AF%86%E6%98%9F%E7%90%83%E5%B9%B3%E5%8F%B0%E4%B8%8A%E4%B9%9F%E5%BC%80%E8%AE%BE%E4%BA%86%E5%8F%91%E7%8E%B0%E9%A1%B5%E9%9D%A2%EF%BC%8C%E9%80%9A%E8%BF%87%E5%90%91%E6%96%B0%E7%94%A8%E6%88%B7%E5%B1%95%E7%A4%BA%E7%B2%BE%E5%8D%8E%E5%86%85%E5%AE%B9%EF%BC%8C%E6%8E%A8%E8%8D%90%E6%98%9F%E7%90%83%EF%BC%8C%E5%B1%95%E7%A4%BA%E6%98%9F%E7%90%83%E6%A6%9C%E5%8D%95%E7%AD%89%E6%96%B9%E5%BC%8F%EF%BC%8C%E5%B8%AE%E5%8A%A9%E6%98%9F%E4%B8%BB%E6%8B%89%E6%96%B0%E5%92%8C%E8%BD%AC%E5%8C%96%E3%80%82))
- 【29】 Rajat Tripathi, _What are Vector Embeddings - Pinecone_ – _解释向量表示能让语义相似性转化为向量空间中的距离，并适用于推荐等任务_