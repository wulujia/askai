+++
date = '2025-02-20T12:10:30+08:00'
draft = false
title = 'AI LLM 入门论文推荐'
+++

我是一个试图学习和理解 AI 技术的文科生，你能不能给我推荐 10 篇论文，是你认为最近三年来，对 AI、LLM 最重要的，必须学习的论文，而且，最好入门门槛不要太高，学习曲线不要太陡峭。

> 我可以为你推荐最近三年内关于 AI 和 LLM（大语言模型）最重要且适合入门学习的论文。在此之前，请确认以下几点：
> 
> 1. 你对 AI 和 LLM 了解的程度？（完全零基础 / 有一定了解 / 相关领域学习者）
> 2. 你希望这些论文更偏向哪方面？（例如：技术原理、应用实践、伦理影响、社会影响等）
> 3. 你希望论文的数学和编程难度如何？（完全避免数学推导 / 适量涉及 / 任何难度都可以）
> 
> 这样我可以更精准地为你筛选适合的论文。

1. 有一定了解
2. 我暂时不关心伦理影响，其他方面比较感兴趣
3. 尽量避免，但如果论文很重要，适量涉及也是可以的

> 感谢你的详细反馈！我会筛选最近三年内关于 AI 和 LLM（大语言模型）最重要的论文，确保它们涵盖技术原理、应用实践等关键领域，同时尽量降低数学和编程门槛，让文科生也能较为顺利地理解。
> 
> 稍后我会整理并分享 10 篇推荐的论文，并提供它们的摘要或核心内容介绍，帮助你更快地掌握这些重要研究。

# 最近三年 AI 和大语言模型领域的十大重要论文

以下列出了 2022–2025 年间 AI 尤其是大语言模型（LLM）领域最重要的十篇论文。这些论文涵盖了技术原理和应用实践，对理解近年 AI 与 LLM 的发展至关重要。每篇论文都尽量选取了公开获取的来源，并为入门者提供简要解读。

## 1. _Training Language Models to Follow Instructions with Human Feedback_ （2022 年，Long Ouyang 等）

**核心贡献：** 提出了用人类反馈来微调大型语言模型的方法，即 _InstructGPT_ ([[2203.02155] Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155#:~:text=reinforcement%20learning%20from%20human%20feedback,language%20models%20with%20human%20intent))。研究表明，单纯增大模型规模并不能让模型更好地遵循用户意图，大模型往往会产生不真实、有害或不相关的输出。通过使用人类提供的示例和偏好对 GPT-3 进行监督微调和人类反馈强化学习（RLHF），作者将模型对齐到用户指令上。结果令人惊讶：虽然微调后的模型参数只有 13亿，但在人类评价中，它生成的回答质量被偏好程度超过了原本1750亿参数的GPT-3 ([[2203.02155] Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155#:~:text=reinforcement%20learning%20from%20human%20feedback,language%20models%20with%20human%20intent))。同时，微调后的模型在真实率和降低有害输出方面有显著提升 ([[2203.02155] Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155#:~:text=reinforcement%20learning%20from%20human%20feedback,language%20models%20with%20human%20intent))。这证明了“模型对齐”比一味增大模型更重要，揭示了通过人类反馈来提升模型实用性的有效途径。

**入门解读：** 这项工作等于给大型语言模型上了一堂“听话课”。研究者先让人类示范如何正确回答指令，然后让模型学习这些示范，并通过人类对模型输出的排名反馈来进一步优化模型。最终得到的 InstructGPT 模型比原始的 GPT-3 更“小”，但更听从指令、回答更有帮助而且不那么容易产生不当内容。这为后来诸如 ChatGPT 等对话模型奠定了基础：证明了_用人类反馈引导模型_可以让 AI 更贴近人类期望 ([[2203.02155] Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155#:~:text=reinforcement%20learning%20from%20human%20feedback,language%20models%20with%20human%20intent))。对于非技术背景的读者，这体现了AI领域一个重要转变——**质量胜于规模**：有针对性地训练和调教模型，可以让较小的模型表现超过不加引导的超大模型。

## 2. _Training Compute-Optimal Large Language Models_ （2022 年，Jordan Hoffmann 等）

**核心贡献：** 提出了“大模型训练的计算最优策略”，并通过构建名为 _Chinchilla_ 的模型验证了该策略 ([[2203.15556] Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556#:~:text=training%20tokens%20should%20also%20be,improvement%20over%20Gopher))。此前业界热衷于不断增加参数规模（如 GPT-3 有1750亿参数），但这项研究发现很多现有大型模型**“训练不足”**，即相对于其规模，训练语料不够 ([[2203.15556] Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556#:~:text=training%20a%20transformer%20language%20model,uses%20the%20same%20compute%20budget))。作者系统地训练了从7000万到160亿参数不等的400多个模型，发现**在给定计算预算下，模型参数量和训练tokens数量应当同比例增加**才能最优 ([[2203.15556] Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556#:~:text=the%20recent%20focus%20on%20scaling,1))。据此预测，他们训练了一个更小但训练数据量更大的模型 Chinchilla（70亿参数，用4倍于一般的大数据训练），在相同计算成本下**全面超越**了当时更大的模型（如2800亿参数的Gopher、1750亿参数的GPT-3等）在各项基准测试中的表现 ([[2203.15556] Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556#:~:text=training%20tokens%20should%20also%20be,improvement%20over%20Gopher))。例如，Chinchilla 在学术基准测试 MMLU 上达到 67.5% 的新水平，比之前最大的模型高出7个百分点 ([[2203.15556] Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556#:~:text=tasks,improvement%20over%20Gopher))。这表明，与其无限制地增大模型，不如提高训练数据量，二者平衡才能发挥最佳效果。

**入门解读：** 通俗来说，这篇论文告诉我们“大脑”不一定越大越好，**喂给大脑的“知识”多少也同样关键**。研究者发现之前的很多大模型就像读书太少的学生，脑子很大但书没读够。而 Chinchilla 模型证明了**小一点的模型如果读了4倍的书，反而比那些大脑袋模型表现更好** ([[2203.15556] Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556#:~:text=training%20tokens%20should%20also%20be,improvement%20over%20Gopher))。对于学习者来说，这奠定了日后训练模型的新准则：盲目扩展参数规模不如合理分配计算预算，让模型多“读书”（训练语料）来弥补认知。这一发现影响了后来模型的设计，例如后来很多研究开始注重数据规模和质量，而不是仅追求参数数量。

## 3. _PaLM: Scaling Language Modeling with Pathways_ （2022 年，Aakanksha Chowdhery 等）

**核心贡献：** 谷歌提出了当时规模空前的**5400亿参数**的Transformer模型 _PaLM_，展示了大规模模型在各种任务上的强大few-shot学习能力 ([[2204.02311] PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/abs/2204.02311#:~:text=demonstrate%20continued%20benefits%20of%20scaling,model%20scale%2C%20meaning%20that%20performance))。PaLM 使用谷歌 Pathways 系统在6144块TPU上训练，充分利用了跨TPU集群的并行计算。该模型在超过100项自然语言理解和生成基准上取得了**新的状态-of-the-art**，尤其在需要多步推理的任务上有突破性性能 ([[2204.02311] PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/abs/2204.02311#:~:text=benchmarks,model%20scale%2C%20meaning%20that%20performance))。值得注意的是，PaLM 540B 在一些任务上**超越了经过专门微调的现有最优模型**，在“大型基准 (BIG-bench)”测试中甚至达到或超过了人类平均水平 ([[2204.02311] PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/abs/2204.02311#:~:text=benchmarks,model%20scale%2C%20meaning%20that%20performance))。另外，作者观察到随着模型规模增长，许多任务的性能出现了**非线性跃升**（即“涌现”能力）：某些复杂任务在小模型上几乎完全不会，但在超大模型PaLM上突然变得可解。 ([[2204.02311] PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/abs/2204.02311#:~:text=benchmarks,model%20scale%2C%20meaning%20that%20performance))

**入门解读：** _PaLM_ 可以看作是“大力出奇迹”的典型案例。研究团队打造了一个参数规模远超前人的模型，并证明了**更大的模型配合足够的训练可以突然学会以前不会的本领** ([[2204.02311] PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/abs/2204.02311#:~:text=benchmarks,model%20scale%2C%20meaning%20that%20performance))。比如，在数学推理等复杂问题上，PaLM 不用专门训练就能仅靠提示达到人类水平。这相当于一个AI模型读了海量书籍后，举一反三能力大增，甚至能胜任一些需要推理的工作。这项研究让大家看到了模型规模带来的潜力和**“涌现能力”**现象，即AI在达到某种规模后会突然掌握新技能。这为后来更大模型（如GPT-4）的出现提供了信心，同时也提醒研究者注意**规模效应**：训练超级大的模型可能带来质的飞跃。

## 4. _Chain-of-Thought Prompting Elicits Reasoning in Large Language Models_ （2022 年，Jason Wei 等）

**核心贡献：** 提出了一种**提升大语言模型复杂推理能力**的简单方法：_思维链提示（Chain-of-Thought, CoT）_ ([[2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903#:~:text=,parameter))。作者发现，如果在提示中示范让模型逐步写出中间推理步骤（即“链式思考”过程），大型模型就能显著更好地解决算术、常识推理和符号推理等复杂任务 ([[2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903#:~:text=,parameter))。实验证明，只有参数规模足够大的模型才能从这种策略中受益，小模型基本不奏效 ([[2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903#:~:text=,parameter))。比如，在数学单词题基准 GSM8K 上，给一个5400亿参数的模型（PaLM）提供8个包含思维链的示例，模型的准确率达到当时**最先进水平**，甚至**超越了**经过专门微调并带验证器的GPT-3模型 ([[2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903#:~:text=large%20language%20models%20show%20that,3%20with%20a%20verifier))。这说明，通过在提示中引导模型“想步骤”，可以自然地**激发出**大型模型潜在的推理能力，而不需要额外训练 ([[2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903#:~:text=,parameter))。

**入门解读：** 思维链提示法的思想很直观：就像人解题要写草稿、大声分析思路一样，我们让AI模型在回答时也先一步步地“想出来” ([[2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903#:~:text=,parameter))。具体做法是在提示里给模型一些例子，这些例子里人类把推理过程分解成了多步。大型模型看到这种示范，就学会了先列步骤再给答案的模式。结果证明，大模型一旦学会“链式思考”，**复杂题也能迎刃而解**，好比一个学生学会草稿演算就能解决更难的题。这对非技术人士来说揭示了一个关键点：**提示方式也能深刻影响AI的能力**。Chain-of-Thought 方法现在被广泛用于提高AI在数学、推理题上的准确率，也是许多对话机器人在回答复杂问题时背后的技巧之一。

## 5. _BLOOM: A 176B-Parameter Open-Access Multilingual Language Model_ （2022 年，BigScience 团队，Teven Le Scao 等）

**核心贡献：** 由数百名研究者协作开发的**多语言开放大模型** _BLOOM_，参数规模达1760亿 ([[2211.05100] BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100#:~:text=towards%20democratizing%20this%20powerful%20technology%2C,under%20the%20Responsible%20AI%20License))。BLOOM 的诞生标志着大型语言模型从科技巨头独占走向了**民主化** ([[2211.05100] BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100#:~:text=these%20capabilities%20have%20led%20to,results%20after%20undergoing%20multitask%20prompted))。该模型完全使用开放的数据集训练，涵盖了46种自然语言和13种编程语言 ([[2211.05100] BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100#:~:text=176B,under%20the%20Responsible%20AI%20License))。BLOOM 在诸多基准上取得了与同等规模的闭源模型**相当的性能** ([[2211.05100] BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100#:~:text=hundreds%20of%20sources%20in%2046,under%20the%20Responsible%20AI%20License))。更重要的是，作者以开放科学的精神**公开发布了模型权重和代码**（采用Responsible AI开源许可） ([[2211.05100] BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100#:~:text=hundreds%20of%20sources%20in%2046,under%20the%20Responsible%20AI%20License))。这使学术界和公众可以免费使用、分析和改进如此大规模的模型，填补了开源社区中千亿级模型的空白。BLOOM 证明了通过众包协作和公共资源，也能训练出接近顶尖水准的超大模型。

**入门解读：** _BLOOM_ 可以说是AI界的“开源里程碑”。以前这么大的语言模型只有大公司有，但BLOOM由约1000名志愿者在法国主导的项目中共同训练完成，相当于AI领域的“协作造塔” ([[2211.05100] BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100#:~:text=towards%20democratizing%20this%20powerful%20technology%2C,under%20the%20Responsible%20AI%20License))。它不仅会英文，还精通法语、西班牙语、中文等几十种语言，以及多种编程语言。这对入门者的意义在于：现在任何人都可以获得这样一个强大的模型来学习和试验，而不必局限于少数公司的接口。BLOOM 的成功表明**开源社区的力量**：大家一起贡献数据和计算资源，也能打造出高水准的AI模型。这加速了AI教育和平民开发创新应用的进程，降低了研究AI的大模型的门槛。

## 6. _Competition-Level Code Generation with AlphaCode_ （2022 年，Yujia Li 等，DeepMind）

**核心贡献：** DeepMind 开发了 _AlphaCode_ 系统，证明大型语言模型在**生成计算机代码**方面已达到中级程序员水准 ([[2203.07814] Competition-Level Code Generation with AlphaCode](https://arxiv.org/abs/2203.07814#:~:text=evaluations%20on%20recent%20programming%20competitions,on%20program%20behavior%20to%20a))。AlphaCode 专注于**竞赛编程题**的自动解答。它通过大规模训练，使模型能够理解复杂的自然语言题目并规划解题算法 ([[2203.07814] Competition-Level Code Generation with AlphaCode](https://arxiv.org/abs/2203.07814#:~:text=perform%20poorly%20when%20evaluated%20on,key%20components%20were%20critical%20to))。在 Codeforces 编程竞赛平台的模拟评测中，AlphaCode 创造了历史：它的成绩平均可排在参赛者的**前54.3%**，也就是超过了一半的人类参赛者 ([[2203.07814] Competition-Level Code Generation with AlphaCode](https://arxiv.org/abs/2203.07814#:~:text=evaluations%20on%20recent%20programming%20competitions,an%20extensive%20and%20clean%20competitive))。实现这一点的关键包括：(1) 使用了一个大规模、高质量的竞赛编程题数据库进行训练；(2) 利用高效的Transformer架构生成**海量候选程序**；(3) 设计了自动的程序执行和筛选机制，从生成的代码中挑选出通过测试用例的解答 ([[2203.07814] Competition-Level Code Generation with AlphaCode](https://arxiv.org/abs/2203.07814#:~:text=than%205%2C000%20participants,on%20program%20behavior%20to%20a))。这是首次有AI在需要算法推理的编程竞赛任务上达到人类平均水平，展示了大语言模型在代码合成和问题求解领域的强大潜力。

**入门解读：** _AlphaCode_ 展现了AI编程的新高度：让模型读遍海量的编程题和答案，然后**学会自己写程序**。简单来说，AlphaCode解题时会生成很多不同的程序解法（就像学生想到很多可能的答案）然后逐一运行测试，最后挑出通过所有测试的程序提交 ([[2203.07814] Competition-Level Code Generation with AlphaCode](https://arxiv.org/abs/2203.07814#:~:text=than%205%2C000%20participants,on%20program%20behavior%20to%20a))。这种“生成+测试”的策略结合强大的代码模型，使它能解决相当复杂的编程难题。对于非技术背景的人，这意味着AI不只能聊天翻译，还开始具备**解决逻辑难题和写代码的能力**了。AlphaCode 的成功让人们看到，大语言模型可以扩展到编程领域，未来有望辅助甚至自动完成部分软件开发任务。当然，这也提醒我们这些模型需要大量测试来确保生成代码的正确性。但毫无疑问，这是AI从文本对话走向更复杂智能应用的重要一步。

## 7. _GPT-4 Technical Report_ （2023 年，OpenAI 团队）

**核心贡献：** OpenAI 发布了 GPT-4 技术报告，介绍了其新一代大模型 GPT-4 的能力和性能 ([[2303.08774] GPT-4 Technical Report](https://arxiv.org/abs/2303.08774#:~:text=,optimization%20methods%20that%20behave%20predictably))。GPT-4 是一个**多模态**模型，能够接受图像和文字输入，输出文字 ([[2303.08774] GPT-4 Technical Report](https://arxiv.org/abs/2303.08774#:~:text=,4%20is%20a))。在各类专业和学术基准测试中，GPT-4 展现出了**接近人类水平**的表现 ([[2303.08774] GPT-4 Technical Report](https://arxiv.org/abs/2303.08774#:~:text=capable%20than%20humans%20in%20many,optimization%20methods%20that%20behave%20predictably))。例如，它在模拟律师资格考试中成绩位于人类考生的前10% ([[2303.08774] GPT-4 Technical Report](https://arxiv.org/abs/2303.08774#:~:text=capable%20than%20humans%20in%20many,optimization%20methods%20that%20behave%20predictably))，在许多高级别考试（如大学入学考试、AP考试等）中也达到了优秀水平。这表明 GPT-4 在理解和推理复杂问题上有了质的飞跃。此外，GPT-4 通过后期的对齐（alignment）训练，生成内容的真实性和遵循道德规范的程度相较以前模型明显改善 ([[2303.08774] GPT-4 Technical Report](https://arxiv.org/abs/2303.08774#:~:text=simulated%20bar%20exam%20with%20a,optimization%20methods%20that%20behave%20predictably))。尽管OpenAI并未公开GPT-4的详细架构和训练细节，但报告充分展示了它在语言理解、推理、代码、数学和视觉理解等方面的**全面领先**性能。GPT-4 被视为迄今最强大的通用AI模型之一。

**入门解读：** GPT-4 可以被看作是通向**通用人工智能**迈出的一大步。它不仅能聊天问答，还能看图说话、写代码、通过各种考试。简单来说，如果把先前的GPT-3比作聪明的高材生，那么GPT-4已经表现出专家级的水准，在法律、医学、数学等考试中都能得高分 ([[2303.08774] GPT-4 Technical Report](https://arxiv.org/abs/2303.08774#:~:text=,optimization%20methods%20that%20behave%20predictably))。这对于普通学习者意味着AI工具变得更加强大可靠：例如，它可以帮助解答更复杂的问题，提供更准确的分析。然而，值得注意的是GPT-4仍有局限，某些现实场景下还是不如人。但总体而言，GPT-4技术报告向世人证明了**大型语言模型的上限**远比想象中高——AI已开始在很多知识领域逼近人类水平。这也解释了为什么2023年以来，我们看到各种基于GPT-4的应用蓬勃兴起，从专业助理到教育助手，AI 正在变得越来越实用和可信。

## 8. _LLaMA: Open and Efficient Foundation Language Models_ （2023 年，Hugo Touvron 等，Meta）

**核心贡献：** Meta AI 发布了 _LLaMA_，一系列**开放的基础语言模型**（7B～65B参数） ([[2302.13971] LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971#:~:text=,models%20to%20the%20research%20community))。LLaMA 模型只使用公开可获取的数据（语料库达万亿词）进行训练，证明了无需私有数据也能训练出**一流表现**的模型 ([[2302.13971] LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971#:~:text=,models%20to%20the%20research%20community))。在各项基准测试上，LLaMA-13B（130亿参数）的表现**超过**了体量大十倍的GPT-3（1750亿参数） ([[2302.13971] LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971#:~:text=and%20show%20that%20it%20is,models%20to%20the%20research%20community))，LLaMA-65B的性能可媲美当时最好的模型如Chinchilla-70B和PaLM-540B ([[2302.13971] LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971#:~:text=and%20show%20that%20it%20is,models%20to%20the%20research%20community))。尽管参数更少，LLaMA系列通过高效训练和海量数据达到了_SOTA_水准。同时，Meta 将这些模型权重提供给研究界，在获得许可的情况下开放下载 ([[2302.13971] LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971#:~:text=inaccessible%20datasets.%20In%20particular%2C%20LLaMA,models%20to%20the%20research%20community))。LLaMA 的推出极大推动了开源社区对大模型的研究，因为研究人员终于可以在本地运行和微调一个媲美商用模型的强大模型了。

**入门解读：** _LLaMA_ 的出现被誉为“大模型开源元年”。一直以来，最强的AI语言模型都掌握在少数公司手中，而Meta把自家高性能模型直接开放给学术界使用。这意味着研究者和开发者**不再受制于接口**，可以深入研究模型内部或针对特定用途微调。LLaMA特别之处在于：用公开数据也能训练出高质量模型，13B参数的小模型居然打败了175B参数的大模型 ([[2302.13971] LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971#:~:text=and%20show%20that%20it%20is,models%20to%20the%20research%20community))。这告诉我们，模型训练的聪明方法（如结合前述Chinchilla策略）能极大提升效率。对于学习者来说，LLaMA让先进AI更加触手可及。很快地，社区基于LLaMA衍生出了许多定制模型（聊天机器人、编程助手等）。可以说，LLaMA 开启了**开源大模型竞赛**，催生了一系列平价却强大的AI模型，为行业带来了开放创新的繁荣。

## 9. _Llama 2: Open Foundation and Fine-Tuned Chat Models_ （2023 年，Hugo Touvron 等，Meta）

**核心贡献：** _Llama 2_ 是 Meta 在 LLaMA 基础上推出的新一代开源大模型系列，包含预训练模型和通过对话微调的聊天模型（7B～70B参数） ([[2307.09288] Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288#:~:text=,the%20responsible%20development%20of%20LLMs))。Llama 2-Chat 模型经过大量对话数据的监督微调和人类反馈优化，专门针对对话场景进行了优化 ([[2307.09288] Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288#:~:text=pretrained%20and%20fine,the%20responsible%20development%20of%20LLMs))。实验证明，这些开源的聊天模型在大多数基准上**超越了**此前公开的同类模型，在“有用性”和“安全性”的人类评估中也表现良好 ([[2307.09288] Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288#:~:text=optimized%20for%20dialogue%20use%20cases,the%20responsible%20development%20of%20LLMs))。Meta 强调，Llama 2-Chat 在帮助和安全指标上接近封闭的专有聊天模型，足以作为后者的开源替代品 ([[2307.09288] Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288#:~:text=optimized%20for%20dialogue%20use%20cases,the%20responsible%20development%20of%20LLMs))。此外，Meta 提供了详尽的报告描述其微调策略和安全措施，并采用较宽松的许可（允许商用）发布模型，鼓励社区基于 Llama 2 进行开发，同时倡导负责任地使用大模型 ([[2307.09288] Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288#:~:text=optimized%20for%20dialogue%20use%20cases,the%20responsible%20development%20of%20LLMs))。Llama 2 的发布标志着开源社区获得了一个高质量的ChatGPT级别模型，推动了开源聊天机器人的发展。

**入门解读：** 简而言之，_Llama 2_ 相当于开源界的“ChatGPT”。它不仅给出了强大的基础模型，还直接提供了训练好的聊天模型，可以像ChatGPT那样对话回答问题。对于广大开发者和企业来说，这非常重要——因为 Llama 2 **允许商业使用**，大家可以免费将其集成到自己的产品中，而不必受制于OpenAI的收费接口。Llama 2发布后，人们很快发现它的回答质量已经非常接近ChatGPT，这在开源模型中前所未有。因此，Llama 2 大受欢迎，各种基于其改进的版本层出不穷。在技术上，Meta 也公开了他们如何用人类反馈强化学习（RLHF）来调教模型，使其既**乐于帮忙**又**谨慎安全** ([[2307.09288] Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288#:~:text=optimized%20for%20dialogue%20use%20cases,the%20responsible%20development%20of%20LLMs))。对于非技术人士，这表明AI助手正在变得**更加开放**：不久的将来，人人都可以拥有属于自己的、安全可控的智能对话助手，而不仅仅是使用大公司的产品。

## 10. _QLoRA: Efficient Finetuning of Quantized LLMs_ （2023 年，Tim Dettmers 等）

**核心贡献：** 提出了 _QLoRA_ 方法，大幅降低大型语言模型微调所需的算力和内存 ([[2305.14314] QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314#:~:text=,innovations%20to%20save%20memory%20without))。QLoRA 将预训练语言模型权重压缩为4比特的精度（量化），冻结原模型参数，仅通过插入的低秩适配器（LoRA）来进行微调，从而在**单张48GB GPU**上就能微调高达650亿参数的模型，同时**几乎不损失**性能 ([[2305.14314] QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314#:~:text=,innovations%20to%20save%20memory%20without))。论文展示了使用QLoRA微调得到的“Guanaco”聊天模型：只用一个GPU训练24小时，就在Vicuna基准上达到**相当于ChatGPT 99.3%水准**的效果 ([[2305.14314] QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314#:~:text=preserving%20full%2016,innovations%20to%20save%20memory%20without))。QLoRA 的创新包括提出了针对正态分布权重优化的4-bit数据格式（NF4）和“双重量化”技术，以及内存分页优化器等 ([[2305.14314] QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314#:~:text=Rank%20Adapters,providing%20a%20detailed%20analysis%20of))，在不影响微调效果的前提下将显存需求降到极低。作者利用QLoRA对上千个模型进行了实验，结果表明即使较小的模型，只要用QLoRA在高质量小数据集上微调也能胜过以往的大模型结果 ([[2305.14314] QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314#:~:text=QLoRA%20to%20finetune%20more%20than,evaluate%20the%20performance%20levels%20of))。他们开源了全部代码和模型，使研究者可以廉价地微调大模型。QLoRA 被视为 democratizing LLM 的利器，让更多人有能力训练属于自己的大模型。

**入门解读：** 过去，如果你想微调一个像GPT-3那样大小的模型，可能需要数张昂贵的GPU卡和复杂的分布式训练。而QLoRA的出现改变了这一局面。它的方法有点像“给大模型做手术减肥”：把模型的内部数字表示压缩得很小很小（4比特），这样模型占的内存就变小了，再**锁定原有知识不变**，只在旁边加上一些小模块学新知识。这样一来，一台普通高端游戏显卡就能担负微调如此庞大模型的任务 ([[2305.14314] QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314#:~:text=,innovations%20to%20save%20memory%20without))！对于开发者和科研人员来说，QLoRA大大降低了成本，让**定制大模型**不再是巨头的专利。哪怕是个人电脑，如今也有可能 fine-tune 一个数十亿参数的模型来完成特定任务。这推动了各种本地化大模型应用的诞生。例如，有人用QLoRA在一天内微调出了医学问答模型、法律助手模型等专业领域AI。总之，QLoRA 为“大模型平民化”提供了工具，加速了AI应用在各行各业的落地。 ([[2305.14314] QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314#:~:text=preserving%20full%2016,innovations%20to%20save%20memory%20without))

**参考文献：** 上述内容引用和根据论文原文整理，包括 ([[2203.02155] Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155#:~:text=reinforcement%20learning%20from%20human%20feedback,language%20models%20with%20human%20intent)) ([[2203.15556] Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556#:~:text=training%20tokens%20should%20also%20be,improvement%20over%20Gopher)) ([[2204.02311] PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/abs/2204.02311#:~:text=benchmarks,model%20scale%2C%20meaning%20that%20performance)) ([[2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903#:~:text=large%20language%20models%20show%20that,3%20with%20a%20verifier)) ([[2211.05100] BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/abs/2211.05100#:~:text=towards%20democratizing%20this%20powerful%20technology%2C,under%20the%20Responsible%20AI%20License)) ([[2203.07814] Competition-Level Code Generation with AlphaCode](https://arxiv.org/abs/2203.07814#:~:text=evaluations%20on%20recent%20programming%20competitions,on%20program%20behavior%20to%20a)) ([[2303.08774] GPT-4 Technical Report](https://arxiv.org/abs/2303.08774#:~:text=,optimization%20methods%20that%20behave%20predictably)) ([[2302.13971] LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971#:~:text=and%20show%20that%20it%20is,models%20to%20the%20research%20community)) ([[2307.09288] Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288#:~:text=pretrained%20and%20fine,the%20responsible%20development%20of%20LLMs)) ([[2305.14314] QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314#:~:text=,innovations%20to%20save%20memory%20without))等出处。读者可通过引用编号查阅相关论文的公开摘要或全文，以获取更深入的了解。上述论文大多可在 arXiv 等开放平台获取。希望这些论文和解读有助于加深您对近年 AI 和大语言模型演进的理解。